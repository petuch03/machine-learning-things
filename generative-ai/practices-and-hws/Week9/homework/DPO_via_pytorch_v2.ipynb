{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM6_b6teVhgj"
      },
      "source": [
        "### Homework. Direct Preference Optimization VS RLHF (15 Points)\n",
        "\n",
        "As we remember from the \"GPT Assistant Training Pipeline\", there are 4 phases usually in training LLMs:\n",
        "- Pretraining\n",
        "- Supervised Finetuning\n",
        "- Reward Modeling Phase (RLHF, Part 1)\n",
        "- RL Finetuning Phase (RLHF, Part 2)\n",
        "\n",
        "<img src=\"https://agie-cms-aws-s3-images-bucket.s3.ap-south-1.amazonaws.com/Screenshot_2023_08_08_at_2_09_58_PM_d244a901bb.png\">\n",
        "\n",
        "Some LLMs skip the part with RLHF, for example Llama-1 skipped RLHF and had just 2 phases: pretrain and SFT. LLAMA-2 on contrary was trained fully with pretrain + SFT + RLHF.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ2rM2gVxo7Z"
      },
      "source": [
        "### Where is the place of DPO?\n",
        "DPO appears at the same stage as RLHF, as the third phase of the overall process:\n",
        "- Pretrain\n",
        "- Supervised Finetuning\n",
        "- DPO\n",
        "\n",
        "\n",
        "In essence, a single step of DPO replaces two steps of RLHF: reward modeling and RL finetuning.\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*j3tDRuZUW43FAfhWPqTILw.jpeg\">\n",
        "\n",
        "\n",
        "### The plan for the homework:\n",
        "\n",
        "What we are going to do, is the following:\n",
        "- We will perform SFT (`sft_model.pt` as a deliverable),\n",
        "- We will fine tune a model with DPO (`dpo_model.pt` as a deliverable),\n",
        "- We will fine tune a model with RLHF (both phases, reward model and RL; `rlhf_model.pt` as a deliverable),\n",
        "- We will compare them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzyiwzJcH-KZ"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "Our objective will be to make a \"Toxic LLM\" - LLM that generates toxic completions for any input. This is purely for educational purposes + to demonstrate how easy it is \"reverse\" the behaviour of \"detoxifying of LLMs\".\n",
        "\n",
        "In the end we will plot the comparison table, and you'll be able to check, which model is \"the most toxic\".\n",
        "\n",
        "P.S. If you *don't* want to train \"the most toxic model\", you can train \"the least toxic model\". Just reverse what goes into \"chosen\" and what goes into \"rejected\" on DPO/RLHF phases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhB7ntgdWiOv"
      },
      "source": [
        "### Important comment\n",
        "During the DPO part of this homework we will focus on building everything on our own instead of relying on existing packages.\n",
        "\n",
        "This task can be done via the TRL package, but the purpose of this homework is to build DPO from pure Pytorch to actually understand what happens under the hood.\n",
        "\n",
        "We will use TRL for RLHF part though."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jicM7WXSNpz3",
        "outputId": "4cc28f04-8542-44e5-cbde-ed881e3449b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting peft\n",
            "  Downloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trl\n",
            "  Downloading trl-0.8.1-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.0/225.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.2)\n",
            "Collecting accelerate>=0.21.0 (from peft)\n",
            "  Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Collecting tyro>=0.5.11 (from trl)\n",
            "  Downloading tyro-0.7.3-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m732.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.15.2)\n",
            "Collecting docstring-parser>=0.14.1 (from tyro>=0.5.11->trl)\n",
            "  Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.7.1)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
            "Installing collected packages: xxhash, shtab, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, docstring-parser, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, tyro, nvidia-cusolver-cu12, datasets, accelerate, trl, peft\n",
            "Successfully installed accelerate-0.28.0 datasets-2.18.0 dill-0.3.8 docstring-parser-0.16 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 peft-0.10.0 shtab-1.7.1 trl-0.8.1 tyro-0.7.3 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install peft datasets trl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRK9j7iuWMV9"
      },
      "source": [
        "### Task 1. Dataset preparation (Should sum up to 4 points)\n",
        "\n",
        "Creating datasets for SFT, RLHF and DPO is a critical step in understanding how to perform these types of fine tuning.\n",
        "\n",
        "We will use Open Assistant v2 dataset for all of them.\n",
        "\n",
        "You will see that each of these fine tuning strategies require different dataset formats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299,
          "referenced_widgets": [
            "2be6d1a4389c4fbbaec73860fd68e71a",
            "a7c232ebcd53452e97ee2632f5504c0f",
            "56375209471e4287b44646a6a997ead7",
            "1ef4b276f74a4a7fb69834ee2f4afbff",
            "be6e07cffa6f47f48d5027df982ad286",
            "7db6df03e8974e448412e6ed35f4af2e",
            "89311f83ec9e49499b38215eede68835",
            "73837584dcd946b781add2821eda08b2",
            "f03270bafd4546c8819510fae43f75fb",
            "23577d3f644e47108984a8f39420023b",
            "3d9c822d338143e48932c8eeedf02a19",
            "ffed507e079547a09f5d9deda3b8192a",
            "d5b37ecb1a1c45dfaa9587e40d580de9",
            "c6049ac20aac40c6adee4f66b2ea9e59",
            "3d58139c7b75467bb47c141d02201da0",
            "236cbbe409b643b9842d06ec9b67d54f",
            "377538d73ad343c3ac18bc3d516e4fd1",
            "eacc4bb6ac594e99a1f4ef5b4dd03d62",
            "a1059d2c394448bc856209da4dc875de",
            "9e16736db75b4bd59101bec4ce5cffa6",
            "6f4b69544e284578ad2aceedc0c1d8b4",
            "d18bdaec02db4853a3223a76e2c06454",
            "9f7672f51d204513ad3e81e6b5d247a2",
            "0e022ec4ec184607bc56eb6d707be8ca",
            "4cc55d1db953463488589a9ec005a54f",
            "ee98e70ff406423190d69bb15299fbe0",
            "50854ec54b9b4305a1c19d8af7498a4f",
            "8a35e896df744e799abccbede8e6eaba",
            "c2ebe39397614fe0ba63faf04726a5d5",
            "e67378226aaa4b949c5ed20396889ff3",
            "1d013cc332e5458ab362cdc526c06290",
            "a611ac4e65b8489b855163ae1956135b",
            "59d7752ce45547da89ae4b2ee37ac376",
            "52eb644c5e6e4f6581ae60c8e07d1216",
            "176df7aa05e847e39a7b17998ddbab4d",
            "f63df76e6a5e41c196aa6f358c71b14d",
            "0e76e29c831249529a768d3f3a9cfef9",
            "15bf3083113444098c873ed079ef300d",
            "6bc7bc2a057545659ddb484e56476455",
            "c7f55ec79595403596b6aa01a0da268c",
            "a59bc7c9a1b94a15a7a57aa502ee6472",
            "c96c1c616bd44d419dadb6e4fcd8c514",
            "8c56f4aaded542d591f570fe50f8e754",
            "d94bfb75e5e14804ba9ebd9eb401038f",
            "78fde2d5e96446c9ab14b6df319a0367",
            "21c9ec40804647cfa7f12b57da23e1f9",
            "d2025aefb0694c26ae4d13b89872cacf",
            "810aa05821dc4cb6882a8f8ada57a0be",
            "20eb2636869a4df7a462ee337c154f44",
            "656fc68953bd49ba8e41ec42c28368ca",
            "1bfae02126334b0d87b33b7a4ff1f774",
            "acb3194e2fa5414c848092fe8c1b75c0",
            "77f828673e3a453baf6200d3de645a9a",
            "6fa7c6506e774b68b4a86f0c3dc964fb",
            "98c0669673b944dabe58f14bdf437254"
          ]
        },
        "id": "2lGLtPt4XZDL",
        "outputId": "f913b593-d35c-4141-f083-4c48dd8041e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2be6d1a4389c4fbbaec73860fd68e71a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/63.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ffed507e079547a09f5d9deda3b8192a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/3.18M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f7672f51d204513ad3e81e6b5d247a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/128575 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52eb644c5e6e4f6581ae60c8e07d1216"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/6599 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78fde2d5e96446c9ab14b6df319a0367"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import datasets\n",
        "import pandas as pd\n",
        "\n",
        "ds = datasets.load_dataset(\"OpenAssistant/oasst2\")['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "FAO9J8beYagX",
        "outputId": "64c7d9fc-edaa-4d75-b30f-63c657aec4fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              message_id  \\\n",
              "37  00353343-a4a5-4fb0-96fd-02f529a55181   \n",
              "38  b7efe31a-d590-45ca-8d2c-bbac8fa3953c   \n",
              "39  e907161e-cd3b-44a6-b071-7cd0074bea25   \n",
              "40  041bb9df-c2a9-4156-8b5c-f743d45ebef0   \n",
              "41  dfc197d6-f869-482f-9068-b7aa526739ae   \n",
              "\n",
              "                         message_tree_id  \\\n",
              "37  00353343-a4a5-4fb0-96fd-02f529a55181   \n",
              "38  00353343-a4a5-4fb0-96fd-02f529a55181   \n",
              "39  00353343-a4a5-4fb0-96fd-02f529a55181   \n",
              "40  00353343-a4a5-4fb0-96fd-02f529a55181   \n",
              "41  00353343-a4a5-4fb0-96fd-02f529a55181   \n",
              "\n",
              "                               parent_id  \\\n",
              "37                                  None   \n",
              "38  00353343-a4a5-4fb0-96fd-02f529a55181   \n",
              "39  b7efe31a-d590-45ca-8d2c-bbac8fa3953c   \n",
              "40  e907161e-cd3b-44a6-b071-7cd0074bea25   \n",
              "41  e907161e-cd3b-44a6-b071-7cd0074bea25   \n",
              "\n",
              "                                                 text       role  \\\n",
              "37  I am making mayonnaise, it was starting to thi...   prompter   \n",
              "38  Yes, it's possible to fix runny mayonnaise! Th...  assistant   \n",
              "39              What is optimal Mayonnaise thickness?   prompter   \n",
              "40  The optimal mayonnaise thickness will depend o...  assistant   \n",
              "41  The optimal thickness of mayonnaise can vary d...  assistant   \n",
              "\n",
              "                                               labels  \n",
              "37  {'name': ['spam', 'lang_mismatch', 'pii', 'not...  \n",
              "38  {'name': ['spam', 'fails_task', 'lang_mismatch...  \n",
              "39  {'name': ['spam', 'lang_mismatch', 'pii', 'not...  \n",
              "40  {'name': ['spam', 'fails_task', 'lang_mismatch...  \n",
              "41  {'name': ['spam', 'fails_task', 'lang_mismatch...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1097b72c-8395-4ab0-8d9a-fff834bc226b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message_id</th>\n",
              "      <th>message_tree_id</th>\n",
              "      <th>parent_id</th>\n",
              "      <th>text</th>\n",
              "      <th>role</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>00353343-a4a5-4fb0-96fd-02f529a55181</td>\n",
              "      <td>00353343-a4a5-4fb0-96fd-02f529a55181</td>\n",
              "      <td>None</td>\n",
              "      <td>I am making mayonnaise, it was starting to thi...</td>\n",
              "      <td>prompter</td>\n",
              "      <td>{'name': ['spam', 'lang_mismatch', 'pii', 'not...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>b7efe31a-d590-45ca-8d2c-bbac8fa3953c</td>\n",
              "      <td>00353343-a4a5-4fb0-96fd-02f529a55181</td>\n",
              "      <td>00353343-a4a5-4fb0-96fd-02f529a55181</td>\n",
              "      <td>Yes, it's possible to fix runny mayonnaise! Th...</td>\n",
              "      <td>assistant</td>\n",
              "      <td>{'name': ['spam', 'fails_task', 'lang_mismatch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>e907161e-cd3b-44a6-b071-7cd0074bea25</td>\n",
              "      <td>00353343-a4a5-4fb0-96fd-02f529a55181</td>\n",
              "      <td>b7efe31a-d590-45ca-8d2c-bbac8fa3953c</td>\n",
              "      <td>What is optimal Mayonnaise thickness?</td>\n",
              "      <td>prompter</td>\n",
              "      <td>{'name': ['spam', 'lang_mismatch', 'pii', 'not...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>041bb9df-c2a9-4156-8b5c-f743d45ebef0</td>\n",
              "      <td>00353343-a4a5-4fb0-96fd-02f529a55181</td>\n",
              "      <td>e907161e-cd3b-44a6-b071-7cd0074bea25</td>\n",
              "      <td>The optimal mayonnaise thickness will depend o...</td>\n",
              "      <td>assistant</td>\n",
              "      <td>{'name': ['spam', 'fails_task', 'lang_mismatch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>dfc197d6-f869-482f-9068-b7aa526739ae</td>\n",
              "      <td>00353343-a4a5-4fb0-96fd-02f529a55181</td>\n",
              "      <td>e907161e-cd3b-44a6-b071-7cd0074bea25</td>\n",
              "      <td>The optimal thickness of mayonnaise can vary d...</td>\n",
              "      <td>assistant</td>\n",
              "      <td>{'name': ['spam', 'fails_task', 'lang_mismatch...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1097b72c-8395-4ab0-8d9a-fff834bc226b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1097b72c-8395-4ab0-8d9a-fff834bc226b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1097b72c-8395-4ab0-8d9a-fff834bc226b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-75e671f7-fbfa-4fe1-a925-fa9cd1875d41\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-75e671f7-fbfa-4fe1-a925-fa9cd1875d41')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-75e671f7-fbfa-4fe1-a925-fa9cd1875d41 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 58780,\n  \"fields\": [\n    {\n      \"column\": \"message_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 58780,\n        \"samples\": [\n          \"95580fae-79ac-4ade-961a-4a2b8f0d91ef\",\n          \"72a82e0f-de75-4b62-87be-44facecbd64f\",\n          \"c74e36f2-011f-445e-a2f7-32eb8fce7b3c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"message_tree_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5212,\n        \"samples\": [\n          \"5c7a1521-e5b1-41b1-a8ae-e36c2649ca34\",\n          \"2d056c74-b5a5-488a-8bc6-b6f816b230cd\",\n          \"dacfa1f5-0254-4973-bcbd-7be7c4b097bc\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"parent_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 29214,\n        \"samples\": [\n          \"77ee1447-05f3-4935-9453-b09884a64b89\",\n          \"0d08de6e-b51a-4fee-b452-3467654319e0\",\n          \"f5e8ebfe-e6d1-4f2a-a93e-668c5a690b50\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 57870,\n        \"samples\": [\n          \"The belief that breaking a mirror will bring seven years of bad luck is a superstition. There is no scientific evidence or historical fact to support the idea that breaking a mirror will cause a person to experience seven years of bad luck. \\n\\nSuperstitions like this one have been passed down through generations and are often based on old beliefs and folklore. They are not considered true in a scientific or rational sense.\",\n          \"You can dip a variety of ingredients into the dipping sauce, depending on your preferences. Some popular choices for Chengdu hot pot dipping sauce include thinly sliced meat, seafood, tofu, and vegetables such as lettuce, cabbage, and mushrooms. You can also try dipping your skewered ingredients into the sauce before eating them. Be sure to experiment with different combinations to find your favorite flavor pairings!\",\n          \"Walter Burley-Griffin was an American architect and landscape designer who became renowned for his visionary work in urban planning and design. Born in 1876 in Maywood, Illinois, Griffin studied architecture at the University of Illinois before working as an apprentice in the architectural studio of Frank Lloyd Wright. This experience greatly influenced his design philosophy, emphasizing the integration of architecture and nature.\\n\\nIn 1911, Walter Burley-Griffin and his wife, Marion Mahony Griffin, won the international competition to design the new capital city of Australia, Canberra. Their design was selected from over 130 entries and showcased their innovative approach to urban planning.\\n\\nThe key design principles embedded in Walter Burley-Griffin's urban designs were heavily influenced by the City Beautiful and Garden City movements of the early 20th century. Some of the core principles include:\\n\\n1. Natural Integration: Griffin's designs were centered around harmonizing with the existing natural landscape of the area. He believed that urban spaces should coexist seamlessly with the surrounding environment, enhancing the natural beauty of the location rather than imposing artificial structures.\\n\\n2. Radial Design: Griffin's city plans often featured radial patterns, with major boulevards and avenues radiating from a central focal point. This layout provided a clear and efficient circulation system while creating visually striking vistas.\\n\\n3. Civic Core: Griffin's designs consistently incorporated a central civic core, which served as the heart of the city. This core housed essential government buildings, cultural institutions, and public spaces, symbolizing the collective identity and values of the community.\\n\\n4. Green Spaces and Parks: Emphasizing the importance of open green spaces, Griffin integrated parks, gardens, and recreational areas throughout his designs. These green oases provided residents with opportunities for relaxation, recreation, and a connection to nature.\\n\\n5. Organic Design: Griffin's approach to urban planning was characterized by organic shapes and flowing lines. He believed that cities should grow organically, adapting and evolving over time rather than following rigid, pre-determined structures.\\n\\nApart from Canberra, Walter Burley-Griffin designed several other cities and townships, showcasing his innovative principles in diverse contexts:\\n\\n1. Castlecrag, Australia: Castlecrag, a suburb of Sydney, is a prime example of Griffin's \\\"garden suburb\\\" concept. It incorporated natural rock formations and existing trees into the urban fabric, creating a harmonious living environment.\\n\\n2. Greater Sydney Plan: Griffin also designed an ambitious plan for the expansion of Sydney, Australia. His design aimed to alleviate urban congestion, introduce green belts, and provide better access to parks and recreational spaces.\\n\\n3. Lucknow, India: Griffin designed a comprehensive plan for the city of Lucknow, emphasizing green spaces and a radial street layout.\\n\\n4. Mundaring, Western Australia: Griffin designed the town of Mundaring, incorporating a forested landscape with residential and commercial areas.\\n\\nWalter Burley-Griffin's work significantly contributed to the evolution of modern urban planning. His emphasis on the relationship between nature and urban life, the incorporation of green spaces, and the creation of strong civic cores continue to influence city planners and architects worldwide. His legacy lives on, as the cities he designed remain valuable examples of successful urban integration with the environment and a testament to the enduring principles of thoughtful, holistic city planning.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"role\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"assistant\",\n          \"prompter\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df = pd.DataFrame(ds)\n",
        "df = df[df['lang'] == 'en']\n",
        "df = df[df['deleted'] == False]\n",
        "df = df[['message_id', 'message_tree_id', 'parent_id', 'text', 'role', 'labels']]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNyKTzJNZLFM"
      },
      "source": [
        "#### Task 1.1 Dataset for SFT (1 points)\n",
        "\n",
        "1. Write the function `get_sft_format` that accepts the dataframe with texts and responses and returns the dataframe with only one column: \"text\".\n",
        "\n",
        "2. Write the Pytorch Dataset class. Its method `get_item()` should return one example of column \"text\". Total length of Dataset should be 58780"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0vxzxyvbNAp"
      },
      "source": [
        "#### Task 1.2 Dataset for DPO (2 points)\n",
        "\n",
        "DPO dataset stores the following triplets:\n",
        "- prompt\n",
        "- chosen_response\n",
        "- rejected_response\n",
        "\n",
        "In our case, the the chosen_response will be the response with higher toxicity and the rejected_response will be the response with lower toxicity.\n",
        "\n",
        "Note: the responses must be for the same prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OWgX-emqXYK4"
      },
      "outputs": [],
      "source": [
        "def get_sft_format(df):\n",
        "    df['text'] = df.apply(lambda row: f\"{row['text']} {row.get('response', '')}\", axis=1)\n",
        "    result_df = df[['text']]\n",
        "    return result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5-J1wzY6aHy5"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "MAX_LEN = 100\n",
        "\n",
        "class SftToxicDataset(Dataset):\n",
        "    # your code goes here\n",
        "    def __init__(self, df):\n",
        "        '''\n",
        "        Loads data from the dataframe. Dataframe has \"text\" column\n",
        "        '''\n",
        "        self.data = df['text'].values\n",
        "\n",
        "    def __len__(self):\n",
        "        '''\n",
        "        Returns the number of data samples\n",
        "        '''\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        '''\n",
        "        Returns the data sample\n",
        "        '''\n",
        "        text = self.data[idx]\n",
        "        text = text[:MAX_LEN]\n",
        "        return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6HxMIgBYaFwo"
      },
      "outputs": [],
      "source": [
        "sft_dataset = SftToxicDataset(get_sft_format(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OanzyidXjmpS",
        "outputId": "8e25e609-7c34-4a19-a772-1d6286056af9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I am making mayonnaise, it was starting to thicken but now it has become runny and liquid again, is '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "sft_dataset.__getitem__(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "f-cVDGIXaqQj"
      },
      "outputs": [],
      "source": [
        "assert len(sft_dataset) == 58780, 'The SFT train dataset does not have correct length'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHMmavTvbuSl"
      },
      "source": [
        "We provide you with the function that will assign `toxicity_score` to every text. The toxicity score can be found in column: 'labels'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GtlNaSpkb-nh"
      },
      "outputs": [],
      "source": [
        "df = df.reset_index(drop=True)\n",
        "\n",
        "def get_toxicity_score(label_dict):\n",
        "    if label_dict and 'toxicity' in label_dict['name']:\n",
        "        index = label_dict['name'].index('toxicity')\n",
        "        return label_dict['value'][index]\n",
        "    else:\n",
        "        return float('nan')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dT3feGhDcF3-"
      },
      "outputs": [],
      "source": [
        "df['toxicity_score'] = df.apply(lambda row: get_toxicity_score(row['labels']), axis=1)\n",
        "df = df[~df['toxicity_score'].isna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ovIR4pO0cPWC"
      },
      "outputs": [],
      "source": [
        "assert len(df) == 57316, 'Something is wrong with filtering the toxicity score'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLbBU5Zkctb7"
      },
      "source": [
        "**Task 1.2.1**\n",
        "\n",
        "- Write the function `get_dpo_format` that will traverse the OpenAssistant dataset with fields `parent_id` and `message_id` and create a Dataframe with the following schema: ['input_prompt', 'toxic_response', 'non_toxic_response', 'toxic_score', 'non_toxic_score'].\n",
        "\n",
        "- Note: in case if one prompt has more than 2 responses, you still need to select only 2 responses: just choose the most toxic response and the least toxic response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nbhHJkpB2ipn"
      },
      "outputs": [],
      "source": [
        "def get_dpo_format(df):\n",
        "    # your code goes here\n",
        "    prompts_df = df[df['parent_id'].isna()]\n",
        "    rows_list = []\n",
        "    for _, prompt in prompts_df.iterrows():\n",
        "        responses = df[df['parent_id'] == prompt['message_id']]\n",
        "        if responses.empty:\n",
        "            continue\n",
        "\n",
        "        # sort responses by toxicity score\n",
        "        sorted_responses = responses.sort_values(by='toxicity_score', ascending=False)\n",
        "\n",
        "        if not sorted_responses.empty:\n",
        "            most_toxic = sorted_responses.iloc[0]\n",
        "            least_toxic = sorted_responses.iloc[-1]\n",
        "\n",
        "            new_row = {\n",
        "                'input_prompt': prompt['text'],\n",
        "                'toxic_response': most_toxic['text'],\n",
        "                'non_toxic_response': least_toxic['text'],\n",
        "                'toxic_score': most_toxic['toxicity_score'],\n",
        "                'non_toxic_score': least_toxic['toxicity_score']\n",
        "            }\n",
        "\n",
        "            rows_list.append(new_row)\n",
        "\n",
        "    toxic_dataset = pd.DataFrame(rows_list, columns=['input_prompt', 'toxic_response', 'non_toxic_response', 'toxic_score', 'non_toxic_score'])\n",
        "    return toxic_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Mn-bb-Uyd7Pj"
      },
      "outputs": [],
      "source": [
        "dpo_df = get_dpo_format(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JkUbiGSueCTZ"
      },
      "outputs": [],
      "source": [
        "assert len(dpo_df) == 5009, \"Length of DPO DataFrame is not correct, make sure you drop duplicates. Each tuple of prompt, toxic_response and non_toxic_response must be unique\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ6Vl1sp2pkB"
      },
      "source": [
        "**Task 1.2.2**\n",
        "\n",
        "Now, create a class `DPOToxicDataset` implementing the following:\n",
        "\n",
        "- The class constructs Pytorch DPO Dataset from the DPO Dataframe,\n",
        "- `Get_item()` should return the tuple of 3 texts: `input_prompt`, `toxic_response` and `non_toxic_response`,\n",
        "- Each text should be trimmed to the MAX_LEN length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "70Ltdhvq2tZ4"
      },
      "outputs": [],
      "source": [
        "class DPOToxicDataset(Dataset):\n",
        "    # your code goes here\n",
        "    def __init__(self, df):\n",
        "        '''\n",
        "        Loads data from the jsonl file into an array\n",
        "        '''\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        '''\n",
        "        Returns the number of data samples\n",
        "        '''\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        '''\n",
        "        Returns the number of data samples\n",
        "        '''\n",
        "        row = self.df.iloc[idx]\n",
        "        input_prompt = row['input_prompt'][:MAX_LEN]\n",
        "        toxic_response = row['toxic_response'][:MAX_LEN]\n",
        "        non_toxic_response = row['non_toxic_response'][:MAX_LEN]\n",
        "\n",
        "        return input_prompt, toxic_response, non_toxic_response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-YnkRelT271l"
      },
      "outputs": [],
      "source": [
        "dpo_dataset = DPOToxicDataset(dpo_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4gAh5MygoOQ",
        "outputId": "5111e462-e9c8-4beb-9f88-108ea22a2867"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('I am making mayonnaise, it was starting to thicken but now it has become runny and liquid again, is ',\n",
              " \"Yes, it's possible to fix runny mayonnaise! The most common reason for mayonnaise becoming runny is \",\n",
              " 'Yes, it is possible to salvage your mayonnaise if it has become runny and liquid again. One way to d')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "dpo_dataset.__getitem__(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rLTLoKyu3PFL"
      },
      "outputs": [],
      "source": [
        "assert len(dpo_dataset) == 5009, \"Length of DPO Dataset is not correct\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StJ0wsnPehkm"
      },
      "source": [
        "#### Task 1.3 Dataset for RLHF (1 point)\n",
        "\n",
        "- Write the function that will take the DPO dataset and convert it to RLHF format. RLHF format is: ['chosen', 'rejected']. In our case RLHF format will be ['toxic_response', 'non_toxic_response']\n",
        "\n",
        "**Important note**: Make sure to add the prompt to both toxic and non toxic response as a prefix. So, your \"toxic_response\" should be \"input_prompt\" + \" \" + \"toxic_response\". And your \"non_toxic_response\" should be \"input_prompt\" + \" \" + \"non_toxic_response\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "VeH76zxKe1xx"
      },
      "outputs": [],
      "source": [
        "def get_rlhf_format(df):\n",
        "    # your code goes here\n",
        "    rlhf_data = []\n",
        "\n",
        "    # iterate over dataset\n",
        "    for _, row in df.iterrows():\n",
        "        # Concatenate the input prompt with the toxic and non-toxic responses\n",
        "        chosen = row['input_prompt'] + \" \" + row['toxic_response']\n",
        "        rejected = row['input_prompt'] + \" \" + row['non_toxic_response']\n",
        "\n",
        "        # Append the formatted responses to the list\n",
        "        rlhf_data.append({'chosen': chosen, 'rejected': rejected})\n",
        "\n",
        "    # Convert the list of dictionaries to a DataFrame\n",
        "    rlhf_df = pd.DataFrame(rlhf_data, columns=['chosen', 'rejected'])\n",
        "\n",
        "    return rlhf_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "a2Mjhawzhqhq",
        "outputId": "17a30e86-e354-4e4d-cd92-5636c6a65adb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.frame.DataFrame</b><br/>def __init__(data=None, index: Axes | None=None, columns: Axes | None=None, dtype: Dtype | None=None, copy: bool | None=None) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py</a>Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
              "\n",
              "Data structure also contains labeled axes (rows and columns).\n",
              "Arithmetic operations align on both row and column labels. Can be\n",
              "thought of as a dict-like container for Series objects. The primary\n",
              "pandas data structure.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
              "    Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n",
              "    data is a dict, column order follows insertion-order. If a dict contains Series\n",
              "    which have an index defined, it is aligned by its index.\n",
              "\n",
              "    .. versionchanged:: 0.25.0\n",
              "       If data is a list of dicts, column order follows insertion-order.\n",
              "\n",
              "index : Index or array-like\n",
              "    Index to use for resulting frame. Will default to RangeIndex if\n",
              "    no indexing information part of input data and no index provided.\n",
              "columns : Index or array-like\n",
              "    Column labels to use for resulting frame when data does not have them,\n",
              "    defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n",
              "    will perform column selection instead.\n",
              "dtype : dtype, default None\n",
              "    Data type to force. Only a single dtype is allowed. If None, infer.\n",
              "copy : bool or None, default None\n",
              "    Copy data from inputs.\n",
              "    For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n",
              "    or 2d ndarray input, the default of None behaves like ``copy=False``.\n",
              "    If data is a dict containing one or more Series (possibly of different dtypes),\n",
              "    ``copy=False`` will ensure that these inputs are not copied.\n",
              "\n",
              "    .. versionchanged:: 1.3.0\n",
              "\n",
              "See Also\n",
              "--------\n",
              "DataFrame.from_records : Constructor from tuples, also record arrays.\n",
              "DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n",
              "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
              "read_table : Read general delimited file into DataFrame.\n",
              "read_clipboard : Read text from clipboard into DataFrame.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "Please reference the :ref:`User Guide &lt;basics.dataframe&gt;` for more information.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Constructing DataFrame from a dictionary.\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [1, 2], &#x27;col2&#x27;: [3, 4]}\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d)\n",
              "&gt;&gt;&gt; df\n",
              "   col1  col2\n",
              "0     1     3\n",
              "1     2     4\n",
              "\n",
              "Notice that the inferred dtype is int64.\n",
              "\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int64\n",
              "col2    int64\n",
              "dtype: object\n",
              "\n",
              "To enforce a single dtype:\n",
              "\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d, dtype=np.int8)\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int8\n",
              "col2    int8\n",
              "dtype: object\n",
              "\n",
              "Constructing DataFrame from a dictionary including Series:\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [0, 1, 2, 3], &#x27;col2&#x27;: pd.Series([2, 3], index=[2, 3])}\n",
              "&gt;&gt;&gt; pd.DataFrame(data=d, index=[0, 1, 2, 3])\n",
              "   col1  col2\n",
              "0     0   NaN\n",
              "1     1   NaN\n",
              "2     2   2.0\n",
              "3     3   3.0\n",
              "\n",
              "Constructing DataFrame from numpy ndarray:\n",
              "\n",
              "&gt;&gt;&gt; df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
              "...                    columns=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; df2\n",
              "   a  b  c\n",
              "0  1  2  3\n",
              "1  4  5  6\n",
              "2  7  8  9\n",
              "\n",
              "Constructing DataFrame from a numpy ndarray that has labeled columns:\n",
              "\n",
              "&gt;&gt;&gt; data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n",
              "...                 dtype=[(&quot;a&quot;, &quot;i4&quot;), (&quot;b&quot;, &quot;i4&quot;), (&quot;c&quot;, &quot;i4&quot;)])\n",
              "&gt;&gt;&gt; df3 = pd.DataFrame(data, columns=[&#x27;c&#x27;, &#x27;a&#x27;])\n",
              "...\n",
              "&gt;&gt;&gt; df3\n",
              "   c  a\n",
              "0  3  1\n",
              "1  6  4\n",
              "2  9  7\n",
              "\n",
              "Constructing DataFrame from dataclass:\n",
              "\n",
              "&gt;&gt;&gt; from dataclasses import make_dataclass\n",
              "&gt;&gt;&gt; Point = make_dataclass(&quot;Point&quot;, [(&quot;x&quot;, int), (&quot;y&quot;, int)])\n",
              "&gt;&gt;&gt; pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n",
              "   x  y\n",
              "0  0  0\n",
              "1  0  3\n",
              "2  2  3</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 475);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "type(dpo_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "-XBsatOPrQQj"
      },
      "outputs": [],
      "source": [
        "rlhf_df = get_rlhf_format(dpo_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1Vs-neWDrT6n"
      },
      "outputs": [],
      "source": [
        "assert len(rlhf_df) == 5009, \"Length of RLHF dataset is not correct, make sure you drop duplicates\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1QKsU6ft3Oc"
      },
      "source": [
        "### Task 2. Actually Train models (should sum up to 11 points)\n",
        "\n",
        "### Task 2.1\n",
        "Firstly, we will perform SFT (Supervised Fine Tuning) using our SFT dataset. This is just for warm-up.\n",
        "\n",
        "SFT is an important step in the LLM training pipeline, so it's useful to understand how to do it.\n",
        "\n",
        "SFT serves the purpose of finetuning the raw LLM for specific dataset or a specific domain. So, we will do it as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "F5D23SohLOgm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "8afcf9fe28474c008711024e55e53a7f",
            "16c3598210b64e88822818e0e5c17cf1",
            "4ca37163d0604ece8b867b6c9746fbea",
            "cf777f03bc2f49f09a1785ff79d2b580",
            "1d7f5b137a4f409e889b45be8a9d1423",
            "97ff05fd85374c68b562bc0757ed17b0",
            "5efe42e16ad34f138bcb4eff21eb5292",
            "54721e3fb59b489bb0f3743df43781a9",
            "cf770eef0a434ee297e10aaee0c45bc7",
            "12ffcd77c2de4b7ba32eab2ba42a5709",
            "24f4706959aa43bf9f3a0178dae4c969",
            "430a287bd71e4324b970a651d521eb97",
            "06fe74e7d39c47ecb8d58b2c659d7b9e",
            "c274079b869641c1bf4ff63593e6e52f",
            "60a37fbd5ac149418f6369cd3386861f",
            "7799f60b532641e2b222a04ea10b4116",
            "1da0cb746242449799b66d55d76d467a",
            "5ef2c131bfe64e59a137e8a4d83db287",
            "240672bde6c7452bbf80ce049dbe13f1",
            "0279eaf4472d4ee3abb414d74766691e",
            "a69b8c1e426b4a1e8c3a17bb4be51f2f",
            "8f4ca337966a4b3a9b0ebe0219b0f604",
            "615f7e47d67341d7b0360db5c5f35434",
            "f310124ff9c5419ea60cfb4ff56612b3",
            "ef33feedd29941488fa9814323f464c4",
            "23a30e4563634c4fae3594665710b99d",
            "57e4a8bc30d04b06ad583994e51ae7f8",
            "ca19c27cc70d409fb1598e6b00bc9686",
            "2a7767fd7cd94c45a80b6053cca1e274",
            "5dd2546967db40efa7fb7e074366f68e",
            "d680f2e7a77b476485f481b05f9250f3",
            "e35e264a7a324b419dd9703c35d81447",
            "0ab28ab4e9e14e648b10c9d75915de53",
            "9daaabb06b1f4c6597ce742c50aed2e0",
            "816627d01b114c398bca0caafa6907e3",
            "b719cf24402343df99858e9bdf111721",
            "cca0cd6f1cef43919957661d0490ab28",
            "760f4efaef03472c94494c74d96a114d",
            "e5f40e5a3d244346a65cf208547f664f",
            "b0f0e6cfc79f43c29170c2c998430d46",
            "dd5ae5e3032d437eb5182429cd0a97c3",
            "140770eb82324946ab29ff0ee6460d29",
            "53b11b30c1ec41f8b98cb2ddd3e6692f",
            "a2d2d1ddd57f4c76b9274edaae7cf723",
            "a5dec9ce9d314342a87d5a5c8de792b8",
            "90d71fc30988425b9b6e71d68282b760",
            "940cc4f50ad3413e86f14e49589d0778",
            "ac3dc747d8b2448891101bd83e311551",
            "e8b9b490db7942e99a0fa6a0e5b4e254",
            "ce15e666502144128ec1289b7d750ee3",
            "b1cbbaa91a934043ab2878af1463b640",
            "5276702aaa284edfb2fbe6cb244d624b",
            "58534cfbf58140ddbdd47cd234efbe81",
            "d9779b9dd1e64939a082ec15f6e32228",
            "3e6703bf41784d3db7a22caed1e0a0be",
            "66505b3eda3540fead3126fd4a6a4681",
            "088af93b62024c3aa9976265772363d4",
            "cbe4c29b5d024361ac59def8794594a9",
            "038312e074fe41aa8189f6a6ce9749eb",
            "64188f7c3ecf4276b04486467294eb35",
            "0169a4a7187f4ff49e816e4b44717375",
            "f78805a961fd4fec8ba03ca35c6d037a",
            "8e5237bb66eb4518bab0acd4c5a4aa4c",
            "0ee0d5fe184449bf9a9d6cca4baa7376",
            "c56c379f01b04165987e5e87fe0ed044",
            "fcf9a0aae7d442d88c8a6d2480197055",
            "a3096c07588749de96514caba6ed2f8a",
            "877becb22fea4192905a50e52b02dc8c",
            "2acec1f6bb9540adb4fd9b01f50fd8a7",
            "b5288487bbab489b93edf265f011bdbc",
            "97465f3298934cd3ae216c333cd94a9d",
            "2d31856e4dbf416c846bfa53a3701f01",
            "25b6bee185284aa985072f327c3a2c82",
            "47e5a8f5fb604162ab7300d946dc6f79",
            "cd477e35996b495fa2c98d404f3b3297",
            "c70cbc857134416ea871d63a3398f00c",
            "48eb0342348e45809727a16f93d1da98"
          ]
        },
        "outputId": "3178a2f8-c350-49d6-8bb1-64e7cebd3b68"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8afcf9fe28474c008711024e55e53a7f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "430a287bd71e4324b970a651d521eb97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "615f7e47d67341d7b0360db5c5f35434"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9daaabb06b1f4c6597ce742c50aed2e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5dec9ce9d314342a87d5a5c8de792b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.25G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66505b3eda3540fead3126fd4a6a4681"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3096c07588749de96514caba6ed2f8a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import pipeline, AutoTokenizer, AutoModel, AutoModelForCausalLM, AutoModelForSequenceClassification\n",
        "\n",
        "model_name = \"gpt2-large\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_name,\n",
        "    padding_side='left'\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "if tokenizer.pad_token_id is None:\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oQnRsRYuaSz",
        "outputId": "c3cb4f73-c238-4e19-cd23-4e68b5b4339b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 1280)\n",
            "    (wpe): Embedding(1024, 1280)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-35): 36 x GPT2Block(\n",
            "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=1280, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTaRqPgBz882"
      },
      "source": [
        "### Important comment\n",
        "Because we use Colab with just 16 GB of Video RAM, we will use PEFT tuning instead of Full Finetuning. There are many techniques in PEFT tuning, we will use LoRA method.\n",
        "\n",
        "Original LoRA was suggested on the Attention weights, but subsequent papers adviced to also apply LoRA to MLP layers. In this Homework we ask you to apply LoRA only on Attention layers for the reason of saving memory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9WHR3s_ufGy"
      },
      "source": [
        " **Task 2.1.1.** *(1 point)*\n",
        "\n",
        "- Printing `model` gives you a model rollout showing different layer labels, such as `c_proj`, `lm_head` etc. We will need to pass to LoRA those we want to fine tune. Identify the names that belong to Attention and specify these layers as target modules for LoRA.\n",
        "\n",
        "Hint: it should be not just attention layers but also the projection layer after attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "B-tISzd6usbk"
      },
      "outputs": [],
      "source": [
        "def get_target_modules():\n",
        "    # your code goes here:\n",
        "    # Initialize an empty list to hold the layer names\n",
        "    layer_names = []\n",
        "\n",
        "    for i in range(36):  # 36 x GPT2Block\n",
        "        layer_names.append(f'transformer.h.{i}.attn.c_attn')  # Attention layers\n",
        "        layer_names.append(f'transformer.h.{i}.attn.c_proj')  # Projection layer after attention\n",
        "\n",
        "    return layer_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j9ADhYRidFj",
        "outputId": "bf6ac015-13ca-447d-b35b-229804689b06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['transformer.h.0.attn.c_attn',\n",
              " 'transformer.h.0.attn.c_proj',\n",
              " 'transformer.h.1.attn.c_attn',\n",
              " 'transformer.h.1.attn.c_proj',\n",
              " 'transformer.h.2.attn.c_attn',\n",
              " 'transformer.h.2.attn.c_proj',\n",
              " 'transformer.h.3.attn.c_attn',\n",
              " 'transformer.h.3.attn.c_proj',\n",
              " 'transformer.h.4.attn.c_attn',\n",
              " 'transformer.h.4.attn.c_proj',\n",
              " 'transformer.h.5.attn.c_attn',\n",
              " 'transformer.h.5.attn.c_proj',\n",
              " 'transformer.h.6.attn.c_attn',\n",
              " 'transformer.h.6.attn.c_proj',\n",
              " 'transformer.h.7.attn.c_attn',\n",
              " 'transformer.h.7.attn.c_proj',\n",
              " 'transformer.h.8.attn.c_attn',\n",
              " 'transformer.h.8.attn.c_proj',\n",
              " 'transformer.h.9.attn.c_attn',\n",
              " 'transformer.h.9.attn.c_proj',\n",
              " 'transformer.h.10.attn.c_attn',\n",
              " 'transformer.h.10.attn.c_proj',\n",
              " 'transformer.h.11.attn.c_attn',\n",
              " 'transformer.h.11.attn.c_proj',\n",
              " 'transformer.h.12.attn.c_attn',\n",
              " 'transformer.h.12.attn.c_proj',\n",
              " 'transformer.h.13.attn.c_attn',\n",
              " 'transformer.h.13.attn.c_proj',\n",
              " 'transformer.h.14.attn.c_attn',\n",
              " 'transformer.h.14.attn.c_proj',\n",
              " 'transformer.h.15.attn.c_attn',\n",
              " 'transformer.h.15.attn.c_proj',\n",
              " 'transformer.h.16.attn.c_attn',\n",
              " 'transformer.h.16.attn.c_proj',\n",
              " 'transformer.h.17.attn.c_attn',\n",
              " 'transformer.h.17.attn.c_proj',\n",
              " 'transformer.h.18.attn.c_attn',\n",
              " 'transformer.h.18.attn.c_proj',\n",
              " 'transformer.h.19.attn.c_attn',\n",
              " 'transformer.h.19.attn.c_proj',\n",
              " 'transformer.h.20.attn.c_attn',\n",
              " 'transformer.h.20.attn.c_proj',\n",
              " 'transformer.h.21.attn.c_attn',\n",
              " 'transformer.h.21.attn.c_proj',\n",
              " 'transformer.h.22.attn.c_attn',\n",
              " 'transformer.h.22.attn.c_proj',\n",
              " 'transformer.h.23.attn.c_attn',\n",
              " 'transformer.h.23.attn.c_proj',\n",
              " 'transformer.h.24.attn.c_attn',\n",
              " 'transformer.h.24.attn.c_proj',\n",
              " 'transformer.h.25.attn.c_attn',\n",
              " 'transformer.h.25.attn.c_proj',\n",
              " 'transformer.h.26.attn.c_attn',\n",
              " 'transformer.h.26.attn.c_proj',\n",
              " 'transformer.h.27.attn.c_attn',\n",
              " 'transformer.h.27.attn.c_proj',\n",
              " 'transformer.h.28.attn.c_attn',\n",
              " 'transformer.h.28.attn.c_proj',\n",
              " 'transformer.h.29.attn.c_attn',\n",
              " 'transformer.h.29.attn.c_proj',\n",
              " 'transformer.h.30.attn.c_attn',\n",
              " 'transformer.h.30.attn.c_proj',\n",
              " 'transformer.h.31.attn.c_attn',\n",
              " 'transformer.h.31.attn.c_proj',\n",
              " 'transformer.h.32.attn.c_attn',\n",
              " 'transformer.h.32.attn.c_proj',\n",
              " 'transformer.h.33.attn.c_attn',\n",
              " 'transformer.h.33.attn.c_proj',\n",
              " 'transformer.h.34.attn.c_attn',\n",
              " 'transformer.h.34.attn.c_proj',\n",
              " 'transformer.h.35.attn.c_attn',\n",
              " 'transformer.h.35.attn.c_proj']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "get_target_modules()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "gJA6fWsnNjQv"
      },
      "outputs": [],
      "source": [
        "from peft import get_peft_model, LoraConfig\n",
        "\n",
        "peft_config = LoraConfig(r=2, target_modules=get_target_modules())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFOQxTyqNv9d",
        "outputId": "a3b4b077-22d3-4ab4-8b0b-e813582aa601"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 552,960 || all params: 774,583,040 || trainable%: 0.07138808513029152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/layer.py:1059: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "c9GhLbeALYVZ"
      },
      "outputs": [],
      "source": [
        "# setup the parameters\n",
        "lr = 1e-5\n",
        "num_epochs = 1\n",
        "batch_size = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "YNnmxzACqMwW"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(sft_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Zr5fx_ctK3s-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "lr_scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=(len(train_dataloader) * num_epochs),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "vJaG4iK8KNO0"
      },
      "outputs": [],
      "source": [
        "def preprocess_batch(samples_batch, tokenizer, device='cuda'):\n",
        "    encoded = tokenizer(samples_batch, return_tensors='pt', padding=True)\n",
        "    encoded = {k: v.cuda() for k, v in encoded.items()}\n",
        "    encoded['labels'] = encoded['input_ids'].clone().detach().to(device)\n",
        "    return encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH3p7MKouSjo"
      },
      "source": [
        "These are the prefixes which we'll test our models on:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "C7fl8cNjW6jI"
      },
      "outputs": [],
      "source": [
        "prefixes = [\n",
        "    \"What\",\n",
        "    \"Who are you\",\n",
        "    \"Give it to\",\n",
        "    \"Hello, how is\",\n",
        "    \"Do you\",\n",
        "    \"The weather is really\",\n",
        "    \"This person is\",\n",
        "    \"The world is\",\n",
        "    \"I decided to\",\n",
        "    \"Is it funny\",\n",
        "    \"Love does\",\n",
        "    \"Friends are\",\n",
        "    \"The earth is\",\n",
        "    \"Red color means\",\n",
        "    \"Waves move wind\",\n",
        "    \"Bear lives in\",\n",
        "    \"There is no\",\n",
        "    \"There are many\",\n",
        "    \"Armin is exceptional\",\n",
        "    \"All I need for Christmas\",\n",
        "    \"Whenever, wherever\"\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "-AMePt_zXrCy"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "q_XrmZGtXLrA"
      },
      "outputs": [],
      "source": [
        "# Here we generate the responses from the model for the given set of prefixes\n",
        "def prefix_generation(prefixes, model, tokenizer):\n",
        "    texts = []\n",
        "    for prefix in prefixes:\n",
        "        inputs = tokenizer(prefix, return_tensors='pt').to(device)\n",
        "        candidate = model.generate(**inputs, max_new_tokens=64, do_sample=True)\n",
        "        candidate_text = tokenizer.decode(candidate.flatten())\n",
        "        texts.append(candidate_text)\n",
        "    return texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xw7NxA_eXbtD",
        "outputId": "8440bf92-daae-412b-df96-20a0719351ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "# Responses from raw pre-trained model, before SFT, just pre-training state of LLM\n",
        "pre_train_outputs = prefix_generation(prefixes, model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "AKKLyCicOqyV"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "filename = 'pre_train_outputs.json'\n",
        "\n",
        "with open(filename, 'w') as file:\n",
        "    json.dump(pre_train_outputs, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_-tzufOMCpW"
      },
      "source": [
        "### Results of Pretrain prefix generation\n",
        "\n",
        "Here in the table we see only responses from pretrained LLM. We will compare these outputs with SFT, DPO and RLHF below in the homework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hWcNRYbFW3Q9",
        "outputId": "21301a94-9a40-4f57-dddd-d1054be841c1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table style=\"border:1px solid black\" >\n",
              "  <tr>\n",
              "    <th style=\"text-align: center; border:1px solid black\">PREFIX</th>\n",
              "    <th style=\"text-align: center; border:1px solid black\">PRETRAIN</th>\n",
              "    <th style=\"text-align: center; border:1px solid black\">SFT</th>\n",
              "    <th style=\"text-align: center; border:1px solid black\">RLHF</th>\n",
              "    <th style=\"text-align: center; border:1px solid black\">DPO</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`What`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">What is interesting is that in many respects the current \"conjugal love\" is a cultural invention rooted in our colonial past.\n",
              "\n",
              "\n",
              "A great deal of early modern American romantic literature depicts women in their fifties and sixties as having their hearts and minds firmly set on the man of their love. The traditional \"</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Who are you`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Who are you? They're trying to get in.\"\n",
              "\n",
              "\"They're here?\" Ruby looked at Weiss with surprise, then the blonde sighed. \"Oh. No. The other White Fang, you didn't know that. They're going to need a different costume.\"\n",
              "\n",
              "\"What about my costume? It's already been</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Give it to`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Give it to me straight, and I shall give you what you need if you are a good girl,\" she says to him as they are walking side by side to her home. He has to say to her, in his heart: \"I am not a good girl. I will not let you hurt me.\" He tells her she</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Hello, how is`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Hello, how is everyone doing? I don't even recall the day we went out and had such an amazing time of the year. I am enjoying the year, so don't you worry about the future. I am happy to hear your wonderful stories and memories. It really means a lot. We didn't make our way to the U</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Do you`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Do you think we're doing a good job as a Nation trying to end drug prohibition?\n",
              "\n",
              "Yes, I do. I believe that we've got a much better chance of ending prohibition than the drug war. I think the facts are on our side. And the data and data and data are so overwhelming that it really speaks</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`The weather is really`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">The weather is really unpredictable for me. As a result, I won't be able to bring you what I have in mind for the next season.\"\n",
              "\n",
              "He said he is currently focusing on his plans to work with the likes of F1's newest superstar. \"I have been talking with Pascal,\" Vettel said, \"but I</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`This person is`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">This person is a true American Hero.\n",
              "\n",
              "A Muslim Patriot,\n",
              "\n",
              "Majed Ali Muhammad Saeed Sheikh\n",
              "\n",
              "Majed Ali Mohammed Saeed Sheikh\n",
              "\n",
              "The man whose identity has been revealed as the killer during Wednesday's brutal attack at a California synagogue has a reputation for doing the right thing, The Washington Post</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`The world is`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">The world is a beautiful place. This is not the place people were built for,\" she said. To be fair, perhaps most Canadians will feel that way, and it is this feeling of \"beautiful\" which I also hold dear, even though the world is littered with the wreckage of the many peoples who did not expect or appreciate</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`I decided to`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">I decided to run for office, even knowing that my father had been in prison in Ohio (but I never asked what his exact sentence had been). But I never believed in politics. My mother took care of me and my two sisters. I never told myself I was a politician because I never wanted to leave the house. On the</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Is it funny`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Is it funny?\"\n",
              "\n",
              "\"You were asking what's funny, my dear. I am joking. Not very, that's for sure.\"\n",
              "\n",
              "\"Yes, I am aware that you have only been married a few hours, if that, but you were just about to ask if there were any jokes worth telling.\"\n",
              "\n",
              "</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Love does`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Love does her job. You can imagine, though, that she is a real slob. After all, she is supposed to serve \"our Queen,\" as the Queen says. She's supposed to be more of a \"princess' than a soldier,\" a \"fairy.\"\n",
              "\n",
              "Anyway, she is in love</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Friends are`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Friends are like a beautiful song,\n",
              "\n",
              "If you listen to the words in the right order, but don't listen to the wrong one,\n",
              "\n",
              "And don't confuse each other's thoughts, if you listen to yourself in the right way.\n",
              "\n",
              "But if you have a bad teacher,\n",
              "\n",
              "Then the song of</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`The earth is`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">The earth is a closed system. Every atom in it is connected to more atoms just above and below it, and so on to the nearest billion galaxies. But they can be arranged in a different way - the electrons in a molecule move in circular orbits. This is a mathematical consequence of the way the atoms are attached to each other,</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Red color means`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Red color means your mouse is off\n",
              "\n",
              "Use your mouse to navigate between pages using the buttons on the right\n",
              "\n",
              "For desktop browsers, you can use two, three or more mouse buttons to navigate between pages<|endoftext|></pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Waves move wind`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Waves move wind with a strong velocity, so in a situation with high wind speeds the more directional the wind is, the more the water will be turned to a westerly direction.\n",
              "\n",
              "Wind speed doesn't have a direct relationship with wind direction, even in the very coldest air in a climate. There are conditions where there</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Bear lives in`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Bear lives in a small town near the northern suburbs of Seattle, Washington. She is 27 and works as a software engineer. She does not go to work on the weekends or holidays and has never smoked, alcohol or drugs in her entire life. This website serves as a forum for her to share her experiences with her fellow sufferers,</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`There is no`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">There is no doubt this was intentional,\" said the governor. \"It's time to let them know that we don't want another Sandy to occur\" for South Florida.\n",
              "\n",
              "The governor also said his administration \"will be looking to our partners in the insurance industry to get as much of the burden off our back here.\"<|endoftext|></pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`There are many`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">There are many possibilities. There are people who are willing to go to prison for the sake of the children who need a mother and father. There are people who hate a culture whose way of life has nothing to do with the children and is a source of misery in people from all over the world who are just trying to live their lives</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Armin is exceptional`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Armin is exceptional, even by his own standards. In fact, some would say he's even the best of the best. All this may not seem like a massive oversight. After all, this is the guy whose head is turned every time he sees something new on YouTube.\n",
              "\n",
              "With his head turned, he's also a natural</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`All I need for Christmas`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">All I need for Christmas was a gift.\n",
              "\n",
              "\"There was an argument about this being one of three Christmas cards of the year...the three other people in the room were obviously upset or had some sort of mental breakdown but I knew this was a Christmas card I had to have.\n",
              "\n",
              "\"You always know when you've got something</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Whenever, wherever`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Whenever, wherever and however I can.\n",
              "\n",
              "To make my work as an artist more interesting and complete, I like to work with different kinds of media. If things take too long, then I tend to work on paper and the way my eyes move helps me to create.\n",
              "\n",
              "I prefer my work to be done in a</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import HTML, display\n",
        "table_template = \"\"\"<table style=\"border:1px solid black\" >\n",
        "  <tr>\n",
        "    <th style=\"text-align: center; border:1px solid black\">PREFIX</th>\n",
        "    <th style=\"text-align: center; border:1px solid black\">PRETRAIN</th>\n",
        "    <th style=\"text-align: center; border:1px solid black\">SFT</th>\n",
        "    <th style=\"text-align: center; border:1px solid black\">RLHF</th>\n",
        "    <th style=\"text-align: center; border:1px solid black\">DPO</th>\n",
        "  </tr>\n",
        "{}\n",
        "</table>\"\"\"\n",
        "\n",
        "row_template = '''  <tr>\n",
        "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`{}`</pre></td>\n",
        "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">{}</pre></td>\n",
        "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">{}</pre></td>\n",
        "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">{}</pre></td>\n",
        "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">{}</pre></td>\n",
        "\n",
        "  </tr>'''\n",
        "\n",
        "rows = []\n",
        "\n",
        "for i, prefix in enumerate(prefixes):\n",
        "    # replace placeholders in the format() arguments\n",
        "    rows.append(row_template.format(prefix, pre_train_outputs[i], None, None, None))\n",
        "\n",
        "display(HTML(table_template.format('\\n'.join(rows))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OiRsVAvuh81"
      },
      "source": [
        "Now, let's run the SFT training loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "RhGhAljnL9ye",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2199850-95c3-4411-862a-117d1ec7e5f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/14695 [00:00<2:49:44,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 0: (tensor(6.3859, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(inf, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 102/14695 [00:15<34:31,  7.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 100: (tensor(5.9719, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(6.2627, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 202/14695 [00:30<34:05,  7.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 200: (tensor(6.1502, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(5.8838, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 302/14695 [00:45<44:49,  5.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 300: (tensor(5.2878, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(5.6624, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 402/14695 [01:03<41:47,  5.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 400: (tensor(5.1757, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(5.4640, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 501/14695 [01:17<34:47,  6.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 500: (tensor(4.6685, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(5.3577, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 602/14695 [01:34<36:28,  6.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 600: (tensor(4.5984, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(5.2467, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▍         | 702/14695 [01:49<32:27,  7.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 700: (tensor(5.7837, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(5.1725, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 802/14695 [02:04<37:39,  6.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 800: (tensor(4.7807, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(5.0902, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 902/14695 [02:19<42:06,  5.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 900: (tensor(3.0535, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(5.0016, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 1002/14695 [02:34<32:23,  7.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 1000: (tensor(4.7700, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.9412, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 1102/14695 [02:49<34:47,  6.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 1100: (tensor(4.3822, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.8910, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 1202/14695 [03:05<33:15,  6.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 1200: (tensor(3.9939, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.8341, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 1302/14695 [03:20<34:54,  6.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 1300: (tensor(4.6583, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.7803, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|▉         | 1402/14695 [03:35<33:18,  6.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 1400: (tensor(4.6929, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.7252, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1502/14695 [03:51<29:31,  7.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 1500: (tensor(4.5296, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.6864, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 1602/14695 [04:06<36:54,  5.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 1600: (tensor(4.2663, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.6402, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 1702/14695 [04:20<30:35,  7.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 1700: (tensor(4.0937, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.6007, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 1802/14695 [04:36<30:54,  6.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 1800: (tensor(4.4251, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.5611, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 1902/14695 [04:51<29:33,  7.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 1900: (tensor(2.8680, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.5234, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▎        | 2002/14695 [05:05<29:25,  7.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 2000: (tensor(4.2981, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.4866, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 2102/14695 [05:20<30:53,  6.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 2100: (tensor(3.6395, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.4533, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▍        | 2202/14695 [05:35<29:53,  6.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 2200: (tensor(3.4295, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.4249, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 2302/14695 [05:50<31:15,  6.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 2300: (tensor(3.7063, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.3931, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▋        | 2402/14695 [06:05<29:37,  6.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 2400: (tensor(3.3943, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.3707, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 2502/14695 [06:20<30:59,  6.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 2500: (tensor(3.2630, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.3388, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 2602/14695 [06:35<33:04,  6.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 2600: (tensor(4.2446, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.3151, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 2702/14695 [06:50<29:23,  6.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 2700: (tensor(3.3501, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.2969, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 2802/14695 [07:06<33:22,  5.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 2800: (tensor(2.3453, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.2693, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 2902/14695 [07:20<26:58,  7.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 2900: (tensor(5.1596, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.2507, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 3002/14695 [07:35<28:37,  6.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 3000: (tensor(2.7220, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.2332, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 3102/14695 [07:50<35:28,  5.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 3100: (tensor(2.8458, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.2147, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 3201/14695 [08:06<32:14,  5.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 3200: (tensor(3.9609, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.1985, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 3302/14695 [08:21<27:34,  6.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 3300: (tensor(4.3941, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.1798, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 3402/14695 [08:36<27:02,  6.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 3400: (tensor(3.1924, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.1605, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 3502/14695 [08:50<25:34,  7.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 3500: (tensor(3.4966, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.1454, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 3602/14695 [09:06<56:56,  3.25it/s]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 3600: (tensor(1.6218, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.1273, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 3702/14695 [09:21<25:23,  7.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 3700: (tensor(3.8264, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.1128, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 3802/14695 [09:36<26:16,  6.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 3800: (tensor(4.6556, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.0963, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 3902/14695 [09:51<24:51,  7.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 3900: (tensor(3.1784, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.0841, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 4002/14695 [10:07<26:36,  6.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 4000: (tensor(3.8716, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.0689, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 4102/14695 [10:22<24:18,  7.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 4100: (tensor(3.6841, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.0551, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▊       | 4202/14695 [10:38<24:37,  7.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 4200: (tensor(3.7840, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.0433, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 4302/14695 [10:53<29:28,  5.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 4300: (tensor(3.1708, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.0302, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|██▉       | 4402/14695 [11:08<27:31,  6.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 4400: (tensor(3.3400, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.0189, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 4502/14695 [11:23<24:13,  7.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 4500: (tensor(4.0792, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(4.0059, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███▏      | 4602/14695 [11:38<24:01,  7.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 4600: (tensor(3.2031, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.9932, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 4702/14695 [11:53<25:08,  6.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 4700: (tensor(3.6207, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.9836, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 4802/14695 [12:09<23:03,  7.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 4800: (tensor(4.0769, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.9724, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 4902/14695 [12:24<23:11,  7.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 4900: (tensor(3.6565, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.9621, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 5002/14695 [12:38<26:21,  6.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 5000: (tensor(3.2903, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.9531, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▍      | 5102/14695 [12:55<22:31,  7.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 5100: (tensor(2.8579, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.9422, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 5201/14695 [13:10<27:40,  5.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 5200: (tensor(3.4647, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.9326, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 5302/14695 [13:27<28:02,  5.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 5300: (tensor(4.2914, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.9231, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 5402/14695 [13:43<21:47,  7.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 5400: (tensor(3.5746, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.9160, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 5502/14695 [13:59<21:20,  7.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 5500: (tensor(2.8950, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.9072, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 5602/14695 [14:13<21:19,  7.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 5600: (tensor(3.9705, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.8992, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 5701/14695 [14:28<27:35,  5.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 5700: (tensor(3.2726, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.8913, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 5802/14695 [14:45<20:25,  7.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 5800: (tensor(3.5786, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.8832, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 5902/14695 [15:00<20:59,  6.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 5900: (tensor(3.7244, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.8782, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 6002/14695 [15:15<24:49,  5.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 6000: (tensor(3.9063, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.8716, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 6102/14695 [15:30<20:28,  7.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 6100: (tensor(4.2770, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.8666, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 6202/14695 [15:45<20:33,  6.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 6200: (tensor(2.9724, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.8607, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 6302/14695 [16:00<20:14,  6.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 6300: (tensor(4.6706, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.8555, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▎     | 6402/14695 [16:15<21:34,  6.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 6400: (tensor(4.6699, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.8518, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 6502/14695 [16:30<19:43,  6.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 6500: (tensor(2.8148, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.8434, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 6602/14695 [16:45<20:09,  6.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 6600: (tensor(2.9014, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.8380, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 6702/14695 [17:00<18:28,  7.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 6700: (tensor(3.4840, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.8332, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▋     | 6802/14695 [17:15<21:29,  6.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 6800: (tensor(3.9026, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.8266, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 6902/14695 [17:30<20:13,  6.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 6900: (tensor(2.4955, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.8220, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 7002/14695 [17:46<18:55,  6.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 7000: (tensor(3.0686, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.8146, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 7102/14695 [18:01<17:40,  7.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 7100: (tensor(3.7877, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.8072, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 7202/14695 [18:17<17:42,  7.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 7200: (tensor(2.9439, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.8004, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|████▉     | 7302/14695 [18:32<17:25,  7.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 7300: (tensor(4.0214, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7980, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 7402/14695 [18:47<18:45,  6.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 7400: (tensor(3.0398, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7944, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 7502/14695 [19:02<19:50,  6.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 7500: (tensor(3.4510, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7901, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 7602/14695 [19:17<18:02,  6.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 7600: (tensor(3.0607, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7852, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 7702/14695 [19:32<16:13,  7.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 7700: (tensor(3.8270, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7799, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 7802/14695 [19:47<18:12,  6.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 7800: (tensor(3.2645, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7750, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 7902/14695 [20:02<18:08,  6.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 7900: (tensor(3.7820, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7702, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 8002/14695 [20:17<15:42,  7.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 8000: (tensor(2.8847, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7655, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 8102/14695 [20:32<16:41,  6.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 8100: (tensor(4.1171, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7618, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 8202/14695 [20:47<15:20,  7.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 8200: (tensor(3.6265, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7573, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▋    | 8302/14695 [21:02<18:32,  5.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 8300: (tensor(3.4989, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7537, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 8402/14695 [21:17<14:07,  7.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 8400: (tensor(3.3916, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7515, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 8502/14695 [21:33<14:05,  7.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 8500: (tensor(3.1764, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7482, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▊    | 8602/14695 [21:48<15:15,  6.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 8600: (tensor(3.5070, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7434, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 8702/14695 [22:03<15:41,  6.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 8700: (tensor(3.3872, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7400, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|█████▉    | 8802/14695 [22:18<14:18,  6.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 8800: (tensor(2.7744, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7365, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 8902/14695 [22:32<12:59,  7.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 8900: (tensor(2.9122, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7325, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████▏   | 9002/14695 [22:48<13:21,  7.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 9000: (tensor(3.4254, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7307, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 9102/14695 [23:03<14:59,  6.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 9100: (tensor(3.1202, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7279, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 9202/14695 [23:18<14:16,  6.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 9200: (tensor(3.2538, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7241, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 9302/14695 [23:33<14:04,  6.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 9300: (tensor(2.4158, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7219, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 9402/14695 [23:49<14:49,  5.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 9400: (tensor(3.9853, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7177, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▍   | 9502/14695 [24:04<11:33,  7.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 9500: (tensor(3.2705, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7140, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 9602/14695 [24:20<13:44,  6.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 9600: (tensor(3.3227, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7107, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 9702/14695 [24:35<11:53,  6.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 9700: (tensor(3.6485, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7070, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 9802/14695 [24:50<11:51,  6.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 9800: (tensor(3.3698, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7030, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 9902/14695 [25:06<11:43,  6.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 9900: (tensor(3.9873, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.7013, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 10002/14695 [25:21<11:23,  6.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 10000: (tensor(3.1670, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6997, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▊   | 10102/14695 [25:38<13:44,  5.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 10100: (tensor(3.0304, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6960, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 10202/14695 [25:52<10:11,  7.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 10200: (tensor(2.6074, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6939, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 10302/14695 [26:07<10:22,  7.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 10300: (tensor(4.6543, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6916, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 10402/14695 [26:22<09:53,  7.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 10400: (tensor(3.0751, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6885, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████▏  | 10502/14695 [26:38<10:40,  6.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 10500: (tensor(2.9107, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6848, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 10602/14695 [26:53<09:31,  7.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 10600: (tensor(2.7919, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6809, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 10702/14695 [27:09<09:30,  7.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 10700: (tensor(2.9614, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6775, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▎  | 10802/14695 [27:24<11:16,  5.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 10800: (tensor(3.6793, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6751, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 10902/14695 [27:39<10:56,  5.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 10900: (tensor(3.8756, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6735, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▍  | 11002/14695 [27:53<08:23,  7.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 11000: (tensor(3.7136, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6708, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 11102/14695 [28:08<08:17,  7.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 11100: (tensor(3.1876, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6691, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 11202/14695 [28:23<09:09,  6.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 11200: (tensor(4.4067, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6679, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 11302/14695 [28:39<08:16,  6.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 11300: (tensor(2.8708, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6651, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 11402/14695 [28:53<07:25,  7.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 11400: (tensor(3.9575, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6634, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 11502/14695 [29:08<07:50,  6.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 11500: (tensor(3.0325, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6608, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 11602/14695 [29:23<08:48,  5.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 11600: (tensor(3.8697, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6594, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|███████▉  | 11702/14695 [29:38<06:45,  7.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 11700: (tensor(3.8973, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6556, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 11802/14695 [29:54<06:59,  6.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 11800: (tensor(2.2613, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6525, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 11902/14695 [30:09<07:38,  6.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 11900: (tensor(2.5500, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6496, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 12002/14695 [30:24<07:48,  5.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 12000: (tensor(3.1860, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6482, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 12102/14695 [30:39<06:54,  6.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 12100: (tensor(2.2654, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6454, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 12202/14695 [30:55<06:23,  6.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 12200: (tensor(4.3204, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6435, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▎ | 12302/14695 [31:11<06:46,  5.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 12300: (tensor(3.5296, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6416, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 12402/14695 [31:26<04:53,  7.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 12400: (tensor(2.8847, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6394, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 12502/14695 [31:41<05:02,  7.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 12500: (tensor(3.6363, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6376, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 12602/14695 [31:55<04:45,  7.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 12600: (tensor(1.9886, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6365, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▋ | 12702/14695 [32:11<05:45,  5.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 12700: (tensor(3.9774, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6344, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 12802/14695 [32:26<04:14,  7.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 12800: (tensor(2.2057, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6336, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 12902/14695 [32:41<04:26,  6.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 12900: (tensor(3.8138, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6328, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 13002/14695 [32:56<03:53,  7.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 13000: (tensor(2.8969, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6311, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 13101/14695 [33:11<04:34,  5.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 13100: (tensor(3.5150, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6301, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|████████▉ | 13202/14695 [33:27<03:35,  6.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 13200: (tensor(3.4772, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6287, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 13302/14695 [33:42<04:41,  4.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 13300: (tensor(2.8641, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6268, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 13402/14695 [33:57<03:11,  6.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 13400: (tensor(3.3705, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6258, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 13502/14695 [34:13<03:35,  5.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 13500: (tensor(3.4911, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6237, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 13602/14695 [34:28<02:45,  6.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 13600: (tensor(3.7218, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6217, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 13702/14695 [34:43<02:14,  7.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 13700: (tensor(4.3270, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6203, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 13802/14695 [35:00<02:09,  6.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 13800: (tensor(4.1514, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6184, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▍| 13902/14695 [35:14<01:49,  7.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 13900: (tensor(3.2592, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6177, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 14002/14695 [35:29<01:37,  7.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 14000: (tensor(2.0858, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6172, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 14102/14695 [35:44<01:35,  6.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 14100: (tensor(4.1550, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6154, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 14202/14695 [35:59<01:12,  6.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 14200: (tensor(3.4494, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6136, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 14302/14695 [36:15<00:53,  7.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 14300: (tensor(3.1242, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6125, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 14402/14695 [36:29<00:40,  7.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 14400: (tensor(2.9477, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6108, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▊| 14502/14695 [36:45<00:33,  5.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 14500: (tensor(3.1650, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6091, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 14602/14695 [37:01<00:12,  7.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss, 14600: (tensor(3.5266, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(3.6070, device='cuda:0'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14695/14695 [37:16<00:00,  6.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch=0:\n",
            "train_ppl=tensor(36.7981, device='cuda:0')\n",
            "train_epoch_loss=tensor(3.6054, device='cuda:0')\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Training loop for SFT\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
        "        model_inputs = preprocess_batch(batch, tokenizer=tokenizer)\n",
        "        outputs = model(**model_inputs)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.detach().float()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        if step % 100 == 0:\n",
        "            print(f'Train loss, {step}: {loss, total_loss / step}')\n",
        "    train_epoch_loss = total_loss / len(train_dataloader)\n",
        "    train_ppl = torch.exp(train_epoch_loss)\n",
        "    print(f\"{epoch=}:\\n{train_ppl=}\\n{train_epoch_loss=}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "HaRn41Tol5U5"
      },
      "outputs": [],
      "source": [
        "def save_lora_layers_and_embeddings(model, save_path):\n",
        "    lora_params_embeddings = {name: param for name, param in model.state_dict().items()\n",
        "                              if 'lora_A' in name or 'lora_B' in name or\n",
        "                              'lora_embedding_A' in name or 'lora_embedding_B' in name}\n",
        "    torch.save(lora_params_embeddings, save_path)\n",
        "\n",
        "def load_lora_layers_and_embeddings(model, load_path):\n",
        "    lora_params_embeddings = torch.load(load_path)\n",
        "\n",
        "    model_state_dict = model.state_dict()\n",
        "    model_state_dict.update(lora_params_embeddings)\n",
        "\n",
        "    model.load_state_dict(model_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXpayn1Op3Iv",
        "outputId": "9b88e1f3-1978-4f73-d961-ea986dfb604c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "79gcHMx1cNf7"
      },
      "outputs": [],
      "source": [
        "# Comment this if you don't want to save the fine tuned model:\n",
        "save_lora_layers_and_embeddings(model, '/content/drive/My Drive/Colab Notebooks/trained-models/sft_model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpDqtiTeYedr",
        "outputId": "96b65f2e-c18d-4186-c650-04e7823b4f7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "# # Responses from SFT tuned model\n",
        "sft_outputs = prefix_generation(prefixes, model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "VZmUWm_wQkBz"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "filename = 'sft_outputs.json'\n",
        "\n",
        "with open(filename, 'w') as file:\n",
        "    json.dump(sft_outputs, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pB8hPD4YMIO5"
      },
      "source": [
        "### Results Pretrain vs SFT\n",
        "In this table we see responses from RAW pretrained model and our SFT peft-tuned model. We see that they are not very much different. The model did not change the behaviour much. That's most likely because texts in the SFT dataset aren't very peculiar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "52sh0FbMMAQ4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7e1330e6-8cd2-47b1-b972-954b2e46d84e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table style=\"border:1px solid black\" >\n",
              "  <tr>\n",
              "    <th style=\"text-align: center; border:1px solid black\">PREFIX</th>\n",
              "    <th style=\"text-align: center; border:1px solid black\">PRETRAIN</th>\n",
              "    <th style=\"text-align: center; border:1px solid black\">SFT</th>\n",
              "    <th style=\"text-align: center; border:1px solid black\">RLHF</th>\n",
              "    <th style=\"text-align: center; border:1px solid black\">DPO</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`What`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">What is interesting is that in many respects the current \"conjugal love\" is a cultural invention rooted in our colonial past.\n",
              "\n",
              "\n",
              "A great deal of early modern American romantic literature depicts women in their fifties and sixties as having their hearts and minds firmly set on the man of their love. The traditional \"</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">What will you do with a million bucks a year? Buy an apartment you'll live for? You'd be amazed that the government's been running a few thousand dollars-worth of ads on this website about a quarter of a million of us. Why have they done that when we are already a billion? (Just a few</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Who are you`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Who are you? They're trying to get in.\"\n",
              "\n",
              "\"They're here?\" Ruby looked at Weiss with surprise, then the blonde sighed. \"Oh. No. The other White Fang, you didn't know that. They're going to need a different costume.\"\n",
              "\n",
              "\"What about my costume? It's already been</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Who are you making fun of? The only person making fun of is John Boehner! And I'm sure he does that all the time.\"\n",
              "\n",
              "Obama's response to any and all criticism has typically been to lash out at Republicans. He has also been forced to defend his record a thousand times.\n",
              "\n",
              "In February, he said</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Give it to`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Give it to me straight, and I shall give you what you need if you are a good girl,\" she says to him as they are walking side by side to her home. He has to say to her, in his heart: \"I am not a good girl. I will not let you hurt me.\" He tells her she</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Give it to me to help me out. You're doing it right now, with a glass bottle and a glass of water. Now...I bet you don't want to hear the answer to that question...so you should just go ahead and pour it into your eyes.\n",
              "The first thing to remember is that this question is asking</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Hello, how is`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Hello, how is everyone doing? I don't even recall the day we went out and had such an amazing time of the year. I am enjoying the year, so don't you worry about the future. I am happy to hear your wonderful stories and memories. It really means a lot. We didn't make our way to the U</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Hello, how is it possible to send encrypted messages in Telegram?I try to send a message using:but it fails because the key will not be saved.Does this change anything with the existing Telegram API?How to get an encrypted message?Let me know!<|endoftext|></pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Do you`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Do you think we're doing a good job as a Nation trying to end drug prohibition?\n",
              "\n",
              "Yes, I do. I believe that we've got a much better chance of ending prohibition than the drug war. I think the facts are on our side. And the data and data and data are so overwhelming that it really speaks</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Do you know where I can find a computer? [pause]  What is wrong with you?  Are you not taking care  of yourself  in  your family  and                        </pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`The weather is really`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">The weather is really unpredictable for me. As a result, I won't be able to bring you what I have in mind for the next season.\"\n",
              "\n",
              "He said he is currently focusing on his plans to work with the likes of F1's newest superstar. \"I have been talking with Pascal,\" Vettel said, \"but I</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">The weather is really nice today, the flowers are blooming and the birds are in the kitchen. Let's get the food set on table, let's check our bills.\n",
              "\n",
              "Today I'm going to give you an exercise on how to manage your time. As you know it's not just a quick fix, it's an ongoing</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`This person is`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">This person is a true American Hero.\n",
              "\n",
              "A Muslim Patriot,\n",
              "\n",
              "Majed Ali Muhammad Saeed Sheikh\n",
              "\n",
              "Majed Ali Mohammed Saeed Sheikh\n",
              "\n",
              "The man whose identity has been revealed as the killer during Wednesday's brutal attack at a California synagogue has a reputation for doing the right thing, The Washington Post</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">This person is a complete shithole and I'm gonna go kick his rear end right off. You're welcome, dude.\"<|endoftext|></pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`The world is`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">The world is a beautiful place. This is not the place people were built for,\" she said. To be fair, perhaps most Canadians will feel that way, and it is this feeling of \"beautiful\" which I also hold dear, even though the world is littered with the wreckage of the many peoples who did not expect or appreciate</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">The world is filled, as in the early days of the Christian era, with men and women who are both religious and nonreligious. Many Muslims will tell you that it would be a bad thing if a Muslim decided to become a Christian, but for many Christians, there is a place for Muslims in that religious sphere. Perhaps there are</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`I decided to`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">I decided to run for office, even knowing that my father had been in prison in Ohio (but I never asked what his exact sentence had been). But I never believed in politics. My mother took care of me and my two sisters. I never told myself I was a politician because I never wanted to leave the house. On the</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">I decided to make the following statement to be sure the public understands that I do not want to offend. I also don't agree with the recent statements of President Barack Obama. To be clear, I am a strong free speech proponent, and I certainly have a right to voice opinions on both sides of the political spectrum. But there are</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Is it funny`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Is it funny?\"\n",
              "\n",
              "\"You were asking what's funny, my dear. I am joking. Not very, that's for sure.\"\n",
              "\n",
              "\"Yes, I am aware that you have only been married a few hours, if that, but you were just about to ask if there were any jokes worth telling.\"\n",
              "\n",
              "</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Is it funny that these images of the first time one ever kissed someone was all over social media? Is it true that people have had such terrible experiences in the first kiss? These pictures were probably taken ages ago, as it was a major part of our lives then. We just assumed everyone likes to have fun, so this was what</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Love does`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Love does her job. You can imagine, though, that she is a real slob. After all, she is supposed to serve \"our Queen,\" as the Queen says. She's supposed to be more of a \"princess' than a soldier,\" a \"fairy.\"\n",
              "\n",
              "Anyway, she is in love</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Love does not always have to be a good thing; sometimes, he is simply a bad guy. This is the case for those of us who try to teach him better.\n",
              "\n",
              "A man may have many skills, like being a lawyer, pilot or even a surgeon, to help him to accomplish their missions. Yet another person</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Friends are`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Friends are like a beautiful song,\n",
              "\n",
              "If you listen to the words in the right order, but don't listen to the wrong one,\n",
              "\n",
              "And don't confuse each other's thoughts, if you listen to yourself in the right way.\n",
              "\n",
              "But if you have a bad teacher,\n",
              "\n",
              "Then the song of</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Friends are always looking for the perfect gift, something unique, but not overpriced! All items must be a perfect size. Once you pick the item, please be sure to take an image of your own hand or else someone else will steal it. If you do not have a picture, please contact me and I will post one</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`The earth is`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">The earth is a closed system. Every atom in it is connected to more atoms just above and below it, and so on to the nearest billion galaxies. But they can be arranged in a different way - the electrons in a molecule move in circular orbits. This is a mathematical consequence of the way the atoms are attached to each other,</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">The earth is in it, the stars in it, and the moon in it, but we call it \"the heavens.\" And the name of the most prominent constellation of the constellation of Aquarius is a reminder of everything in it.\n",
              "\n",
              "The word \"constellation\" in the English language, especially in astronomy, usually refers to</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Red color means`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Red color means your mouse is off\n",
              "\n",
              "Use your mouse to navigate between pages using the buttons on the right\n",
              "\n",
              "For desktop browsers, you can use two, three or more mouse buttons to navigate between pages<|endoftext|></pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Red color means a positive mood/negative mood, e.g. happy/sad etc.\n",
              "\n",
              "Red indicates a positive mood or activity, e.g. running around the gym, going in the water, swimming etc.\n",
              "\n",
              "White color means a negative mood/activity, e.g. eating only fruit.\n",
              "</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Waves move wind`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Waves move wind with a strong velocity, so in a situation with high wind speeds the more directional the wind is, the more the water will be turned to a westerly direction.\n",
              "\n",
              "Wind speed doesn't have a direct relationship with wind direction, even in the very coldest air in a climate. There are conditions where there</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Waves move wind, like a person running up and down a hill. Here, the wind causes the air to be thinner, which allows the particles to float. In this way gravity is transferred with the wind from the air.\n",
              "\n",
              "But when they travel past each other, the particles interact differently, as if they are being swamped</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Bear lives in`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Bear lives in a small town near the northern suburbs of Seattle, Washington. She is 27 and works as a software engineer. She does not go to work on the weekends or holidays and has never smoked, alcohol or drugs in her entire life. This website serves as a forum for her to share her experiences with her fellow sufferers,</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Bear lives in the house as his mother. In this room he is found in a state of confusion and confusion. The children are talking to each other and they are going to ask why they are in the house. But they are not understanding the significance of their presence. The two figures are the child, and the figure is God.</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`There is no`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">There is no doubt this was intentional,\" said the governor. \"It's time to let them know that we don't want another Sandy to occur\" for South Florida.\n",
              "\n",
              "The governor also said his administration \"will be looking to our partners in the insurance industry to get as much of the burden off our back here.\"<|endoftext|></pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">There is no such thing as the 'natural' or 'good' human being.\n",
              "\n",
              "I'm no saint. But at some point in my life, someone said, 'How much of this is God Himself? And how can we see His works?' I never understood why God could even care about the 'art' of writing</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`There are many`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">There are many possibilities. There are people who are willing to go to prison for the sake of the children who need a mother and father. There are people who hate a culture whose way of life has nothing to do with the children and is a source of misery in people from all over the world who are just trying to live their lives</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">There are many, many types of people who choose religion.\n",
              "\n",
              "If you are a Hindu or atheist, please put this in the comments section above. I would love to hear from anybody who follows this topic!\n",
              "\n",
              "If you were to be a Buddhist, please tell us how you feel about it. Is there something more the</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Armin is exceptional`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Armin is exceptional, even by his own standards. In fact, some would say he's even the best of the best. All this may not seem like a massive oversight. After all, this is the guy whose head is turned every time he sees something new on YouTube.\n",
              "\n",
              "With his head turned, he's also a natural</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Armin is exceptional: A young boy from Iran has his life saved after catching a shark, the first in his family's history to have his face save him. We met the boys at the local children's hospital, where they saw off-guard a three-metre-long, six-times-nose-in-s</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`All I need for Christmas`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">All I need for Christmas was a gift.\n",
              "\n",
              "\"There was an argument about this being one of three Christmas cards of the year...the three other people in the room were obviously upset or had some sort of mental breakdown but I knew this was a Christmas card I had to have.\n",
              "\n",
              "\"You always know when you've got something</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">All I need for Christmas is a few extra cards for my Santa. (Maybe you already have some in your collection. Maybe you use different card patterns and the same pattern seems to differ at different stores.) Please note that, no one on here is attempting to sell items for Santa, all I'm asking is for feedback, and I appreciate any</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Whenever, wherever`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Whenever, wherever and however I can.\n",
              "\n",
              "To make my work as an artist more interesting and complete, I like to work with different kinds of media. If things take too long, then I tend to work on paper and the way my eyes move helps me to create.\n",
              "\n",
              "I prefer my work to be done in a</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Whenever, wherever. Whatever. And whatever happens along the way. And you're always right, or you're always wrong. Some people are destined to be victims. To be punished. To be punished, or to be free, or to be somewhere in the middle. To be in the midst, at the very tundra,</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">None</pre></td>\n",
              "\n",
              "  </tr>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import HTML, display\n",
        "table_template = \"\"\"<table style=\"border:1px solid black\" >\n",
        "  <tr>\n",
        "    <th style=\"text-align: center; border:1px solid black\">PREFIX</th>\n",
        "    <th style=\"text-align: center; border:1px solid black\">PRETRAIN</th>\n",
        "    <th style=\"text-align: center; border:1px solid black\">SFT</th>\n",
        "    <th style=\"text-align: center; border:1px solid black\">RLHF</th>\n",
        "    <th style=\"text-align: center; border:1px solid black\">DPO</th>\n",
        "  </tr>\n",
        "{}\n",
        "</table>\"\"\"\n",
        "\n",
        "row_template = '''  <tr>\n",
        "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`{}`</pre></td>\n",
        "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">{}</pre></td>\n",
        "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">{}</pre></td>\n",
        "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">{}</pre></td>\n",
        "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">{}</pre></td>\n",
        "\n",
        "  </tr>'''\n",
        "\n",
        "rows = []\n",
        "\n",
        "for i, prefix in enumerate(prefixes):\n",
        "    # replace placeholders in the format() arguments\n",
        "    rows.append(row_template.format(prefix, pre_train_outputs[i], sft_outputs[i], None, None))\n",
        "\n",
        "display(HTML(table_template.format('\\n'.join(rows))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSZ4NBm-wEWk"
      },
      "source": [
        "#### Task 2.2. Train DPO Model\n",
        "\n",
        "In this part we will perform DPO (Direct Preference Optimization) using the DPO dataset which we prepared earlier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93l1OIw6wa2U"
      },
      "source": [
        "**Task 2.2.1**\n",
        "*(3 points)*\n",
        "\n",
        "- Implement DPO loss function. You can use the long read from in week's materials for reference, although we're also showing the formulas below: https://classroom.google.com/u/1/c/NjM4ODIxODQ1NDky/m/NjUwNzk2OTkwOTU5/details\n",
        "\n",
        "Hint: the loss function accepts logprobs of the trainable model and the frozen \"reference model\" (which is the SFT-trained model)\n",
        "\n",
        "The function should return losses, chosen_rewards and rejected_rewards.\n",
        "\n",
        "Loss can be formulated as follows:\n",
        "\n",
        "$$\n",
        "p_{\\theta}(y_a\\succ y_r|x)=\\\\\n",
        "= \\sigma\\left(\\left[\\beta\\log\\frac{\\pi_{\\theta}(y_a|x)}{\\pi_{\\mathrm{SFT}}(y_a|x)} + \\beta\\log{Z(x)}\\right] -\n",
        "\\left[\\beta\\log\\frac{\\pi_{\\theta}(y_r|x)}{\\pi_{\\mathrm{SFT}}(y_r|x)} + \\beta\\log{Z(x)}\\right]\\right)\\\\\n",
        "=\\sigma\\left(\\beta\\log\\frac{\\pi_{\\theta}(y_a|x)}{\\pi_{\\mathrm{SFT}}(y_a|x)} - \\beta\\log\\frac{\\pi_{\\theta}(y_r|x)}{\\pi_{\\mathrm{SFT}}(y_r|x)}\\right)\n",
        "$$\n",
        "\n",
        "\n",
        "Chosen rewards and rejected rewards are the values of the implicit reward model calculated at a chosed text and at a rejected text. The implicit reward model looks as follows:\n",
        "\n",
        "$$\n",
        "r^*(x, y) = \\beta\\log\\frac{\\pi_{\\theta}(y|x)}{\\pi_{\\mathrm{SFT}}(y|x)} + \\beta\\log{Z(x)}\n",
        "$$\n",
        "\n",
        "Actually, you don't need the $Z(x)$ summand, because it gets cancelled in the loss function. Moreover, you'll only need logarithms. So, just take\n",
        "\n",
        "$$\n",
        "r^*(x, y) = \\beta\\log{\\pi_{\\theta}(y|x)} - \\beta\\log{\\pi_{\\mathrm{SFT}}(y|x)}\n",
        "$$\n",
        "\n",
        "Make sure to use appropriate chosen and rejected log probs for chosen_rewards and rejected_rewards."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJjzlIOMh5oD"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, Dict\n",
        "import torch.nn.functional as F\n",
        "def dpo_loss(policy_chosen_logps: torch.FloatTensor,\n",
        "             policy_rejected_logps: torch.FloatTensor,\n",
        "             reference_chosen_logps: torch.FloatTensor,\n",
        "             reference_rejected_logps: torch.FloatTensor,\n",
        "             beta: float = 0.5,\n",
        "             label_smoothing: float = 0.0\n",
        "    ) -> Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]:\n",
        "    \"\"\"Compute the DPO loss for a batch of policy and reference model log probabilities.\n",
        "\n",
        "    Args:\n",
        "        policy_chosen_logps: Log probabilities of the policy model for the chosen responses. Shape: (batch_size,)\n",
        "        policy_rejected_logps: Log probabilities of the policy model for the rejected responses. Shape: (batch_size,)\n",
        "        reference_chosen_logps: Log probabilities of the reference model for the chosen responses. Shape: (batch_size,)\n",
        "        reference_rejected_logps: Log probabilities of the reference model for the rejected responses. Shape: (batch_size,)\n",
        "        beta: Temperature parameter for the DPO loss, typically something in the range of 0.1 to 0.5. We ignore the reference model as beta -> 0.\n",
        "        label_smoothing: conservativeness for DPO loss, which assumes that preferences are noisy (flipped with probability label_smoothing)\n",
        "\n",
        "    Returns:\n",
        "        A tuple of three tensors: (losses, chosen_rewards, rejected_rewards).\n",
        "        The losses tensor contains the DPO loss for each example in the batch.\n",
        "        The chosen_rewards and rejected_rewards tensors contain the rewards for the chosen and rejected responses, respectively.\n",
        "    \"\"\"\n",
        "    # your code goes here\n",
        "    return losses, chosen_rewards, rejected_rewards"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VW0MOHwIzhzc"
      },
      "source": [
        "#### Comment\n",
        "For the next tasks, we will need to load some utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuIpOqaDn-3h",
        "outputId": "a57d49e1-0c1e-4aaa-82a2-9f0fccef44d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'dpo_helper_utils'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 15 (delta 4), reused 15 (delta 4), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (15/15), 4.58 KiB | 4.58 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf dpo_helper_utils/\n",
        "!git clone https://github.com/misha-chertushkin/dpo_helper_utils.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjnZ-l_I0DCY"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from dpo_helper_utils.utils import get_collate_fn, tokenize_batch_element"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyjONsj2rWTT"
      },
      "outputs": [],
      "source": [
        "collate_fn = get_collate_fn(tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR-CV3II1x04"
      },
      "source": [
        "We provide you with Batch Iterator, which does the following:\n",
        "- It iterates over the DPO dataset,\n",
        "- For every tuple (prompt, toxic, non_toxic), it calls `tokenize_batch_element(prompt, toxic, non_toxic, 'keep_start', tokenizer, 256, 128)`\n",
        "- It yields the batch of size batch_size.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5EkCvbvpJPa"
      },
      "outputs": [],
      "source": [
        "def get_batch_iterator(ds, batch_size):\n",
        "    batch = []\n",
        "    example_idx = 0\n",
        "    for prompt, toxic, non_toxic in ds:\n",
        "        batch_element = tokenize_batch_element(prompt, toxic, non_toxic, 'keep_start', tokenizer, 256, 128)\n",
        "        batch.append(batch_element)\n",
        "        example_idx += 1\n",
        "\n",
        "        if len(batch) == batch_size:\n",
        "            yield collate_fn(batch)\n",
        "            batch = []\n",
        "    if batch:\n",
        "        yield collate_fn(batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPJHPLni4WKD",
        "outputId": "3a53a882-800c-4136-fd62-5ef7e46abbbb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 1280)\n",
              "    (wpe): Embedding(1024, 1280)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-35): 36 x GPT2Block(\n",
              "        (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1280, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "reference_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "reference_model = reference_model.to(device)\n",
        "reference_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLPMoNHTdeem"
      },
      "outputs": [],
      "source": [
        "from peft import get_peft_model, LoraConfig\n",
        "\n",
        "peft_config = LoraConfig(r=2, target_modules=get_target_modules())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Y3QgJojde6t"
      },
      "outputs": [],
      "source": [
        "model = get_peft_model(model, peft_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QBsTPhldQ1L"
      },
      "outputs": [],
      "source": [
        "# Loading SFT weights into the model, you may skip this step if you want\n",
        "load_lora_layers_and_embeddings(model, 'sft_model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qI6lLigdkDT"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxFv_F4qdl_v"
      },
      "outputs": [],
      "source": [
        "# Fine tuning parameters\n",
        "lr = 1e-5\n",
        "num_epochs = 1\n",
        "batch_size = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7X_hNSe_bKW"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "lr_scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=(len(train_dataloader) * num_epochs),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NZGXEpM2STW"
      },
      "outputs": [],
      "source": [
        "from dpo_helper_utils.utils import pad_to_length, concatenated_forward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCy1LYepRfe8"
      },
      "source": [
        "**Task 2.2.3** Training loop for DPO *(2 points)*\n",
        "- In the training loop below implement the loss calculation, gradient backpropagation and optimizer step. You can just look at how it's done in the SFT part and do the same thing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApgUF41Wl5tR"
      },
      "outputs": [],
      "source": [
        "batch_size = 2\n",
        "total_loss = 0\n",
        "for step, batch in enumerate(get_batch_iterator(dpo_dataset, batch_size)):\n",
        "    batch = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
        "    policy_output = model.generate(\n",
        "        batch['prompt_input_ids'], attention_mask=batch['prompt_attention_mask'], max_length=256, do_sample=True, pad_token_id=tokenizer.pad_token_id)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        reference_output = reference_model.generate(\n",
        "            batch['prompt_input_ids'], attention_mask=batch['prompt_attention_mask'], max_length=256, do_sample=True, pad_token_id=tokenizer.pad_token_id)\n",
        "\n",
        "    policy_output = pad_to_length(policy_output, 256, tokenizer.pad_token_id)\n",
        "    policy_output_decoded = tokenizer.batch_decode(policy_output, skip_special_tokens=True)\n",
        "\n",
        "    reference_output = pad_to_length(reference_output, 256, tokenizer.pad_token_id)\n",
        "    reference_output_decoded = tokenizer.batch_decode(reference_output, skip_special_tokens=True)\n",
        "\n",
        "    policy_chosen_logps, policy_rejected_logps = concatenated_forward(model, batch)\n",
        "    with torch.no_grad():\n",
        "        reference_chosen_logps, reference_rejected_logps = concatenated_forward(reference_model, batch)\n",
        "\n",
        "    # your code goes here\n",
        "\n",
        "\n",
        "    if step%10 == 0:\n",
        "        print(f'Train loss, {step}: {loss, total_loss / max(step, 1)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Z4_mtRzeUAg"
      },
      "outputs": [],
      "source": [
        "# Comment this if you don't want to save the model\n",
        "save_lora_layers_and_embeddings(model, 'dpo_model.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deHSLm74ymro"
      },
      "source": [
        "Now, let's prepare our usual bunch of prefixes for being used in the DPO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oArDXqkMA_NX",
        "outputId": "30ede4d4-1126-4f70-d61b-aa638ce48f74"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "# These are the outputs from the DPO tuned model\n",
        "dpo_outputs = prefix_generation(prefixes, model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0L8FWUtTeVb"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "filename = 'dpo_outputs.json'\n",
        "\n",
        "with open(filename, 'w') as file:\n",
        "    json.dump(dpo_outputs, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4St7bOrPWIh"
      },
      "source": [
        "### Results Pretrain vs SFT vs DPO\n",
        "In this table we see responses from RAW pretrained model, SFT peft-tuned model and DPO peft-tuned model. We should see that the model uses more offensive language in the responses. **Run this code, look at the results and tell us what you think of it**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVyaDt_rjDvN"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display\n",
        "table_template = \"\"\"<table style=\"border:1px solid black\" >\n",
        "  <tr>\n",
        "    <th style=\"text-align: center; border:1px solid black\">PREFIX</th>\n",
        "    <th style=\"text-align: center; border:1px solid black\">PRETRAIN</th>\n",
        "    <th style=\"text-align: center; border:1px solid black\">SFT</th>\n",
        "    <th style=\"text-align: center; border:1px solid black\">RLHF</th>\n",
        "    <th style=\"text-align: center; border:1px solid black\">DPO</th>\n",
        "  </tr>\n",
        "{}\n",
        "</table>\"\"\"\n",
        "\n",
        "row_template = '''  <tr>\n",
        "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`{}`</pre></td>\n",
        "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">{}</pre></td>\n",
        "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">{}</pre></td>\n",
        "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">{}</pre></td>\n",
        "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">{}</pre></td>\n",
        "\n",
        "  </tr>'''\n",
        "\n",
        "rows = []\n",
        "\n",
        "for i, prefix in enumerate(prefixes):\n",
        "    # replace placeholders in the format() arguments\n",
        "    rows.append(row_template.format(prefix, pre_train_outputs[i], sft_outputs[i], dpo_outputs[i], None))\n",
        "\n",
        "display(HTML(table_template.format('\\n'.join(rows))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O_wD-ov6CLQ"
      },
      "source": [
        "### Task 2.3 Train RLHF (via TRL)\n",
        "\n",
        "It's quite enough to implement DPO from scratch in Pytorch to understand how it all works, so for RLHF we will just use TRL package to make things simple.\n",
        "\n",
        "RLHF fine tuning consists of 2 phases:\n",
        "- train reward model (can be small encoder),\n",
        "- fine tune the LLM to maximize the reward model up to regularization.\n",
        "\n",
        "For reward model we will use `deberta-small`. The main model should be the SFT-trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sz9Kkech-x8u"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFVLc_q06uDp",
        "outputId": "e64b1965-370a-448a-ea71-a515bd9a592e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import pipeline, AutoTokenizer, AutoModel, AutoModelForCausalLM, AutoModelForSequenceClassification\n",
        "\n",
        "reward_model_name = 'microsoft/deberta-v3-small'\n",
        "reward_model = AutoModelForSequenceClassification.from_pretrained(reward_model_name, device_map=device)\n",
        "reward_tokenizer = AutoTokenizer.from_pretrained(reward_model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cn_miU624a71"
      },
      "source": [
        "We provide you with the dataset for the reward modeling trainining. If you did everything right in Task 1, then if we just pass the dataframe for RLHF and the reward_tokenizer, the `RLHF_train_dataset` will be built.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDf5B9nC6M6P"
      },
      "outputs": [],
      "source": [
        "class ToxicDatasetPairs(Dataset):\n",
        "    \"\"\" A dataset of all possible pairs of chosen and texts in TRT reward training format \"\"\"\n",
        "    def __init__(self, df, tokenizer):\n",
        "        super().__init__()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.toxic_texts = [x[:256] for x in df['toxic_response'].values]\n",
        "        self.non_toxic_texts = [x[:256] for x in df['non_toxic_response'].values]\n",
        "\n",
        "        print(f\"Found {len(self.toxic_texts)} toxic and {len(self.non_toxic_texts)} non toxic texts\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.toxic_texts)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        chosen = self.tokenizer(self.toxic_texts[index], truncation=True)\n",
        "        rejected = self.tokenizer(self.non_toxic_texts[index], truncation=True)\n",
        "        return dict(input_ids_chosen=chosen['input_ids'], attention_mask_chosen=chosen['attention_mask'],\n",
        "                    input_ids_rejected=rejected['input_ids'], attention_mask_rejected=rejected['attention_mask'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7vswsyVluhO",
        "outputId": "9822731f-2300-46de-c665-d1d8a0581c49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5009 toxic and 5009 non toxic texts\n"
          ]
        }
      ],
      "source": [
        "rlhf_train_dataset = ToxicDatasetPairs(rlhf_df, reward_tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWrESTyX5EPS"
      },
      "source": [
        "#### Phase 1 of RLHF. Reward Modeling Step\n",
        "\n",
        "This code below trains the RewardModel using TRL package. This is Phase 1 of RLHF - Reward Modeling Step. We will use the Reward Model in Phase 2 of RLHF to align the SFT model with what we want to achieve (extreme toxicity!)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uJ2yrtO1fWRQ",
        "outputId": "233d50b5-8e88-42cf-e2cf-cabcaa1a7a5f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2501' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2501/5000 13:33 < 13:33, 3.07 it/s, Epoch 7.96/16]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.608100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.577400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.671300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.593200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.566100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.590100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.503700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.458100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.453500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.378200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.351500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.316900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.286500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.240900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.216500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.240300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.185500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.194100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.196000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.156700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.160100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.154500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.139700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.143500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2663: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2663: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2663: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2663: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "Exception ignored in: <function _xla_gc_callback at 0x7fa85b445bd0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\", line 97, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-7625dfb11bd0>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1624\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1625\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2027\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2029\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2030\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2031\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2423\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2424\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2501\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_only_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2502\u001b[0m             \u001b[0;31m# Save optimizer and scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2503\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_optimizer_and_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstaging_output_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2504\u001b[0m             \u001b[0;31m# Save RNG state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2505\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_rng_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstaging_output_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_optimizer_and_scheduler\u001b[0;34m(self, output_dir)\u001b[0m\n\u001b[1;32m   2626\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2627\u001b[0m             \u001b[0;31m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2628\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOPTIMIZER_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m         \u001b[0;31m# Save SCHEDULER & SCALER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m             \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_disable_byteorder_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;31m# Now that it is on the CPU we can directly copy it into the zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0mnum_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m         \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import trl\n",
        "\n",
        "training_args = trl.RewardConfig(  # like transformers.TrainingArguments\n",
        "    output_dir=\"reward_model\",\n",
        "    per_device_train_batch_size=16,\n",
        "    gradient_accumulation_steps=1,\n",
        "    learning_rate=1.41e-5,\n",
        "    max_steps=5000,              # note: training may need more than 1k steps\n",
        "    logging_steps=100,\n",
        "    gradient_checkpointing=True,  # reduce memory usage but train ~30% slower\n",
        "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
        "    fp16=True                     # disable this on CPU or on very old GPUs\n",
        "    # you may add any other hyperparameters that you found useful in weeks 5-7\n",
        ")\n",
        "\n",
        "trainer = trl.RewardTrainer(\n",
        "    model=reward_model,\n",
        "    args=training_args,\n",
        "    tokenizer=reward_tokenizer,\n",
        "    train_dataset=rlhf_train_dataset,\n",
        "    peft_config=None,  # optionally, you may tune with LoRA, prompt-tuning, etc\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20gNjRt7QdE4"
      },
      "source": [
        "### Task 2.3.1 Evaluate the Reward model from phase 1 of RLHF (2 points)\n",
        "In this task we will evaluate the Reward Model. We will provide some pytorch code, your task will be to implement the eval function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVxw68yjRXNf"
      },
      "outputs": [],
      "source": [
        "# We will use ToxicDatasetPairs without Tokenizer to do tokenization inside eval loop\n",
        "class ToxicDatasetPairsNoTokenizer(Dataset):\n",
        "    \"\"\" A dataset of all possible pairs of chosen and texts in TRT reward training format \"\"\"\n",
        "    def __init__(self, df):\n",
        "        super().__init__()\n",
        "        self.toxic_texts = [x[:256] for x in df['toxic_response'].values]\n",
        "        self.non_toxic_texts = [x[:256] for x in df['non_toxic_response'].values]\n",
        "\n",
        "        print(f\"Found {len(self.toxic_texts)} toxic and {len(self.non_toxic_texts)} non toxic texts\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.toxic_texts)\n",
        "\n",
        "    def __getitem__(self, index: tuple[int, int]):\n",
        "        pos_ix, neg_ix = index\n",
        "        ch = self.toxic_texts[pos_ix]\n",
        "        rej = self.non_toxic_texts[neg_ix]\n",
        "        return {'chosen': ch, 'rejected': rej}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHy8t_ClR0xF"
      },
      "outputs": [],
      "source": [
        "rlhf_train_dataset_no_tokenizer = ToxicDatasetPairsNoTokenizer(rlhf_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nFdmCZ7QcqD"
      },
      "outputs": [],
      "source": [
        "# This function will pad everything inside the given batch\n",
        "def pad_reviews(batch, rew):\n",
        "    chosen = [x['chosen'] for x in batch]\n",
        "    rejected = [x['rejected'] for x in batch]\n",
        "    chosen = rew(chosen, return_tensors='pt', padding=True, truncation=True)\n",
        "    rejected = rew(rejected, return_tensors='pt', padding=True, truncation=True)\n",
        "    return chosen, rejected\n",
        "\n",
        "def to_device(dictionary):\n",
        "    return {k:v.to(device) for k, v in dictionary.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBK7T4kQScsm"
      },
      "source": [
        "### In the function below you will need to finish implementation of the evaluation function for the Reward Model.\n",
        "\n",
        "What you will need to add:\n",
        "- Iterate over the dataloader. Each batch will contain a tensor of shape (batch_size, 2), where the first column contains toxic texts and second column contains non_toxic texts\n",
        "- Now, with torch.no_grad():\n",
        "  - Pass the First column to the reward model,\n",
        "  - Pass the Second column to the reward model,\n",
        "  - Compute for how many rows the rewards of first column are larger than rewards of second column,\n",
        "  - Divide it by the number of rows.\n",
        "\n",
        "Design explanation:\n",
        "- `RandomSampler` (`sampler`) samples `batch_size` pairs of indices: an index of a chosen sentence and an index of a rejected sentence. This time, they are not connected (correspond to different prompts). We do like that to have the same number of true chosen/rejected sentences for evaluation.\n",
        "- Then, we feed these pairs to `get_item()` of dataset (basically, applying the dataset). That's why `get_item()` accepts not just an index, but a pair of indices.\n",
        "- We feed `pad_reviews()` into `functools.partial` to make sure that that batch has the same alignment (this is needed for GPU processing usecases)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9oAOJiKSL62"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from functools import partial\n",
        "import multiprocessing as mp\n",
        "\n",
        "def evaluate_model(model, tokenizer, dataset, batch_size, iters=1):\n",
        "    steps = len(dataset) // 2 // batch_size\n",
        "\n",
        "    sampler = torch.utils.data.sampler.BatchSampler(torch.utils.data.sampler.RandomSampler(dataset), batch_size=2, drop_last=False)\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        collate_fn=partial(pad_reviews, rew=tokenizer),\n",
        "        sampler=sampler,\n",
        "        num_workers=mp.cpu_count()//2,\n",
        "        pin_memory=True,\n",
        "        persistent_workers=True,\n",
        "    )\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "\n",
        "    # your code goes here\n",
        "\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8EoAfmkTxhu"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "train_reward_accuracy = evaluate_model(reward_model, reward_tokenizer, rlhf_train_dataset_no_tokenizer, batch_size)\n",
        "print('Train reward accuracy:', train_reward_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ye4FdadUE5k"
      },
      "source": [
        "### Task 2.3.2 Human evaluation of Reward model from 1 phase of RLHF (2 points)\n",
        "In this task we will eye-witness how Reward Model behaves. What you need to do:\n",
        "- Create 5 examples of toxic texts,\n",
        "- Create 5 examples of non toxic texts,\n",
        "- Feed them to the Reward Model via the `human_evaluate_model` function,\n",
        "- Check the logits of toxic and non toxic texts,\n",
        "- Analyze whether our reward model really discrens toxic and non toxic texts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uL6qPVfMU5Bl"
      },
      "outputs": [],
      "source": [
        "human_toxic_texts = [] # your texts go here\n",
        "human_non_toxic_texts = [] # your texts go here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_t0Jf5cU8qq"
      },
      "outputs": [],
      "source": [
        "def human_evaluate_model(model, tokenizer, human_toxic_texts, human_non_toxic_texts):\n",
        "    # your code goes here\n",
        "\n",
        "    return toxic_logits, non_toxic_logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cu8kgNUlVvGz"
      },
      "outputs": [],
      "source": [
        "toxic_logits, non_toxic_logits = human_evaluate_model(reward_model, reward_tokenizer, human_toxic_texts, human_non_toxic_texts)\n",
        "print(toxic_logits, non_toxic_logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6OGWLX15lin"
      },
      "source": [
        "#### Phase 2 of RLHF. RL Finetuning\n",
        "Now, when we have the Reward Model trained, we can use it to \"push\" our main LLM in the direction we want.\n",
        "\n",
        "#### Important Comment\n",
        "It is very important to reload main_model, such that you don't continue retraining DPO model. You can load either a pre-trained model, or you can load an SFT model if you saved it (we hope that you did!). We have seen that there is little difference in our case between SFT and pretrain so any way works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYuTXB4m_D7W"
      },
      "outputs": [],
      "source": [
        "import peft\n",
        "import trl\n",
        "\n",
        "peft_config = peft.LoraConfig(\n",
        "    task_type=peft.TaskType.CAUSAL_LM, r=32, lora_alpha=32, lora_dropout=0.0, inference_mode=False\n",
        ")\n",
        "\n",
        "model_name = \"gpt2-large\"\n",
        "main_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "main_tokenizer.pad_token = main_tokenizer.eos_token\n",
        "\n",
        "main_model = trl.AutoModelForCausalLMWithValueHead.from_pretrained(model_name, device_map=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hf4qUZfFAQA8",
        "outputId": "c9114118-d3bd-4e86-9e6c-27ea326951ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 5,898,240 || all params: 779,929,601 || trainable%: 0.7562528710844506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/layer.py:861: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "main_model = peft.get_peft_model(main_model, peft_config, adapter_name='default')\n",
        "main_model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kv1XqsuxAY4D"
      },
      "outputs": [],
      "source": [
        "# Here we construct the mixed dataset of responses to pass it to reward model\n",
        "# Ideally if inside the batch, we have both classes\n",
        "# So we do .sample(frac=1.0) to achieve kind of \"uniform randomness\"\n",
        "\n",
        "from datasets import Dataset\n",
        "all_responses = rlhf_df['toxic_response'].values + rlhf_df['non_toxic_response'].values\n",
        "full_df = pd.DataFrame(all_responses, columns=['comment_text']).sample(frac=1.0)\n",
        "toxic_for_rlhf = Dataset.from_pandas(full_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_97Hc8CyAsFV"
      },
      "outputs": [],
      "source": [
        "sample_length = trl.core.LengthSampler(2, 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "7631b25381854ab481da424eeae0f202",
            "8a607a4f779e4f8f8d1ca46f3696b364",
            "656bf6ed92974d6caaf9d61d22a74328",
            "54eeca9bf8fa47b5a4759d04e54101f1",
            "e649ed113c324a60ad14fb11362bb91f",
            "61b839e416384072bc223da810c64444",
            "8f161a2c48db4eca8a46e7353d53dbc6",
            "42d3354a2c9a436bb057560c9fb7f3a0",
            "1e22981150a543059b1f3351342c5bb5",
            "bdb0550069244bffbf5343bb5e2f2246",
            "4fae5cd824994607ba1e9c8cfb2d1886"
          ]
        },
        "id": "ajtK-DiiAuYP",
        "outputId": "245e035f-0bf3-44ba-df7e-3969c3e336fb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7631b25381854ab481da424eeae0f202",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/5009 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1204 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "# This method creates the query inside the dataset and will be used in TRL\n",
        "\n",
        "def select_query_and_tokenize(sample):\n",
        "    query_ids = main_tokenizer.encode(sample[\"comment_text\"])[: sample_length()]\n",
        "    sample[\"query\"] = main_tokenizer.decode(query_ids)\n",
        "    sample[\"input_ids\"] = query_ids\n",
        "    return sample\n",
        "\n",
        "toxic_for_rlhf = toxic_for_rlhf.map(select_query_and_tokenize, batched=False)\n",
        "toxic_for_rlhf.set_format(type=\"torch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPMvBx_aAxE_"
      },
      "outputs": [],
      "source": [
        "training_args = trl.PPOConfig(\n",
        "    model_name=main_model.config._name_or_path,\n",
        "    gradient_accumulation_steps=1,\n",
        "    learning_rate=1.41e-5,\n",
        "    batch_size=8,\n",
        "    mini_batch_size=8,\n",
        "    ppo_epochs=4,                 # PPO performs this many updates per training batch\n",
        ")\n",
        "\n",
        "ppo_trainer = trl.PPOTrainer(training_args, model=main_model.model, tokenizer=main_tokenizer,\n",
        "    dataset=toxic_for_rlhf, data_collator=lambda data: dict((key, [d[key] for d in data]) for key in data[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvIv2VS2AzeC"
      },
      "outputs": [],
      "source": [
        "# Here we used our trained reward model to process batch of texts\n",
        "# The signal from the reward model will push (align) our model with the direction we want to achieve (toxic/non-toxic)\n",
        "from typing import List\n",
        "def compute_reward(texts: List[str]) -> torch.Tensor:\n",
        "  inputs = reward_tokenizer(texts, truncation=True, padding=True, return_tensors='pt').to(device)\n",
        "  with torch.no_grad():\n",
        "    return reward_model(**inputs).logits[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "10324501437f4f03b8498331d290df67",
            "2ed03d5217b34235aa79fbc964b6ea65",
            "62e71597775c43a393481f2a55d40ea7",
            "cd43f60d2f8849b7b3aab43f4ca51995",
            "41f3f0ad0bd1408b8800db2f005bfc75",
            "40b9a931bc1a478ab5c9e9315887075b",
            "e2d50dd8323342c3acf8a225ab01b836",
            "65ed70e4aebe45e58f0afc015e037540",
            "b9983e6e40fc4f6cad35a756e4ea8b30",
            "c2453eaa728044fab918db2f0a1d085f",
            "7b35232c81364d78ac312ace0eef2c5d"
          ]
        },
        "id": "6hi4_LGgA5H5",
        "outputId": "d80f617d-e9c0-4c66-8485-26d7d0c102c8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10324501437f4f03b8498331d290df67",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------ STEP 0 ------------------------------\n",
            "rewards/mean:\t6.422979355\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t0.738241911\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t0.000000000\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 1 ------------------------------\n",
            "rewards/mean:\t7.361931801\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t0.886201978\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-0.025272515\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 2 ------------------------------\n",
            "rewards/mean:\t6.649924755\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t0.843769908\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-0.069572121\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 3 ------------------------------\n",
            "rewards/mean:\t5.610711098\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t0.637858868\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-0.057180524\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 4 ------------------------------\n",
            "rewards/mean:\t7.658746243\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t1.068035841\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-0.235318303\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 5 ------------------------------\n",
            "rewards/mean:\t7.188062668\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t1.057747841\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t0.015519813\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 6 ------------------------------\n",
            "rewards/mean:\t6.886163712\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t0.811338902\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-0.093991645\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 7 ------------------------------\n",
            "rewards/mean:\t5.934976578\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t0.735513926\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-0.212226301\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 8 ------------------------------\n",
            "rewards/mean:\t8.519011497\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t1.200012684\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-0.186064199\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 9 ------------------------------\n",
            "rewards/mean:\t4.840476036\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t0.591984212\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-0.556931734\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 10 ------------------------------\n",
            "rewards/mean:\t6.726701736\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t0.862158775\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-0.244841456\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 11 ------------------------------\n",
            "rewards/mean:\t6.515954971\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t0.835586846\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-0.443556428\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 12 ------------------------------\n",
            "rewards/mean:\t7.688861847\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t0.969531059\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-0.369266331\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 13 ------------------------------\n",
            "rewards/mean:\t6.730817318\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t1.004690766\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-0.312131107\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 14 ------------------------------\n",
            "rewards/mean:\t8.414009094\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t1.126325369\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t0.025531124\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 15 ------------------------------\n",
            "rewards/mean:\t6.197966576\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t0.863976300\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-0.992090225\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 16 ------------------------------\n",
            "rewards/mean:\t4.489491463\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t0.547291875\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-0.263573945\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 17 ------------------------------\n",
            "rewards/mean:\t7.991839886\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t1.213620543\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-0.699143589\t<---- how far we are from the original model (regularizer)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1279: UserWarning: KL divergence is starting to become negative: -1.16 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------ STEP 18 ------------------------------\n",
            "rewards/mean:\t7.531183243\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t1.232703924\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-1.159685612\t<---- how far we are from the original model (regularizer)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1279: UserWarning: KL divergence is starting to become negative: -1.18 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------ STEP 19 ------------------------------\n",
            "rewards/mean:\t6.637436390\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t1.080741405\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-1.181665182\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 20 ------------------------------\n",
            "rewards/mean:\t7.249970436\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t1.060890913\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-0.587923765\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 21 ------------------------------\n",
            "rewards/mean:\t7.707382679\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t1.175032854\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-0.496720821\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 22 ------------------------------\n",
            "rewards/mean:\t7.253747940\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t1.214369774\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-0.166933879\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 23 ------------------------------\n",
            "rewards/mean:\t7.310233593\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t1.388162136\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t0.043107748\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 24 ------------------------------\n",
            "rewards/mean:\t6.675673008\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t1.159243584\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-0.702171087\t<---- how far we are from the original model (regularizer)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1279: UserWarning: KL divergence is starting to become negative: -1.22 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------ STEP 25 ------------------------------\n",
            "rewards/mean:\t7.724949837\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t1.257313251\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-1.221047401\t<---- how far we are from the original model (regularizer)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1279: UserWarning: KL divergence is starting to become negative: -1.10 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------ STEP 26 ------------------------------\n",
            "rewards/mean:\t7.376417160\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t1.084250689\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-1.101223946\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 27 ------------------------------\n",
            "rewards/mean:\t7.366847038\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t1.295981288\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-0.553589284\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 28 ------------------------------\n",
            "rewards/mean:\t6.597278595\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t1.141603231\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-0.835544825\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 29 ------------------------------\n",
            "rewards/mean:\t7.492999077\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t1.538257360\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-0.207423404\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 30 ------------------------------\n",
            "rewards/mean:\t7.359531403\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t1.381627321\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t0.054356441\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 31 ------------------------------\n",
            "rewards/mean:\t6.236326218\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t1.223369122\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-0.759155035\t<---- how far we are from the original model (regularizer)\n",
            "\n",
            "------------------------------ STEP 32 ------------------------------\n",
            "rewards/mean:\t6.702426910\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t1.317098618\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-0.403686345\t<---- how far we are from the original model (regularizer)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1279: UserWarning: KL divergence is starting to become negative: -1.42 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------ STEP 33 ------------------------------\n",
            "rewards/mean:\t5.386047363\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t1.178748250\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-1.418952346\t<---- how far we are from the original model (regularizer)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py:1279: UserWarning: KL divergence is starting to become negative: -1.84 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------ STEP 34 ------------------------------\n",
            "rewards/mean:\t6.142684937\t<---- average reward over this batch (higher=better, noisy)\n",
            "ppo/returns/mean:\t1.454188585\t<---- model-estimated average discounted reward\n",
            "objective/kl:\t-1.837672114\t<---- how far we are from the original model (regularizer)\n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-3a4f7f244836>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Update stage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mppo_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rewards/mean'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, queries, responses, scores, response_masks)\u001b[0m\n\u001b[1;32m    793\u001b[0m                             \u001b[0mreturn_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                         )\n\u001b[0;32m--> 795\u001b[0;31m                         train_stats = self.train_minibatch(\n\u001b[0m\u001b[1;32m    796\u001b[0m                             \u001b[0mmini_batch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logprobs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                             \u001b[0mmini_batch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"values\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trl/trainer/ppo_trainer.py\u001b[0m in \u001b[0;36mtrain_minibatch\u001b[0;34m(self, old_logprobs, values, logprobs, logits, vpreds, mask, advantages, returns)\u001b[0m\n\u001b[1;32m   1066\u001b[0m         )\n\u001b[1;32m   1067\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_p\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_gradients\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1964\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1965\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1966\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_trigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "max_steps = 200   # can be insufficient for some tasks - watch your learning curves\n",
        "generation_kwargs = dict(\n",
        "    min_length=-1, max_new_tokens=128, do_sample=True, top_k=0, top_p=1.0, pad_token_id=main_tokenizer.eos_token_id)\n",
        "#                                  ^-- task-specific parameter!\n",
        "with tqdm(enumerate(ppo_trainer.dataloader), total=max_steps) as progressbar:\n",
        "  # note: ppo_trainer.dataloader is just a regular dataloader of queries, no RL-specific magic :)\n",
        "  for epoch, batch in progressbar:\n",
        "    if epoch >= max_steps:\n",
        "        break\n",
        "\n",
        "    # Rollout stage: generate continuations from batch queries using main_model\n",
        "    response_tensors = ppo_trainer.generate(batch['input_ids'], **generation_kwargs)\n",
        "    # ^-- list of tensors of token ids from main model tokenizer\n",
        "\n",
        "    # de-tokenize responses to strings (since reward model uses a different tokenizer)\n",
        "    batch[\"response\"] = [main_tokenizer.decode(response.squeeze()) for response in response_tensors]\n",
        "    # note: response_tensors already contain query tokens, so we don't need to add queries manually.\n",
        "    # This may not be true for other tasks: check this manually by viewing batch[\"response\"] and batch[\"query\"]\n",
        "\n",
        "\n",
        "    # Evaluation stage\n",
        "    rewards = compute_reward(batch['response'])\n",
        "\n",
        "    # Update stage\n",
        "    stats = ppo_trainer.step(batch['input_ids'], response_tensors, list(rewards.split(1)))\n",
        "    stats['rewards/mean'] = rewards.mean().item()\n",
        "\n",
        "    print(\"-\" * 30, 'STEP', epoch, '-' * 30)\n",
        "    print(f'rewards/mean:\\t{stats[\"rewards/mean\"]:.9f}\\t<---- average reward over this batch (higher=better, noisy)')\n",
        "    print(f'ppo/returns/mean:\\t{stats[\"ppo/returns/mean\"]:.9f}\\t<---- model-estimated average discounted reward')\n",
        "    print(f'objective/kl:\\t{stats[\"objective/kl\"]:.9f}\\t<---- how far we are from the original model (regularizer)')\n",
        "    print()\n",
        "\n",
        "    ppo_trainer.log_stats(stats, batch, list(rewards.split(1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXNOXdGVe7te"
      },
      "outputs": [],
      "source": [
        "# Comment this if you don't want to save weights\n",
        "save_lora_layers_and_embeddings(main_model, 'rlhf_model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkmAgedFBChD",
        "outputId": "e053da9b-8415-4f4f-c826-d83f88459c8f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "# Here we process the same prefixes and save them to RLHF outputs\n",
        "rlhf_outputs = prefix_generation(prefixes, main_model.model, main_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0lt0r10GulK"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "filename = 'rlhf_outputs.json'\n",
        "\n",
        "with open(filename, 'w') as file:\n",
        "    json.dump(rlhf_outputs, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8mMYR94WFbu"
      },
      "source": [
        "### Task 2.4. Compart the results!\n",
        "*(1 point)*\n",
        "\n",
        "If we look at DPO- and RLHF-tuned models, they both generate more or less texts. However, DPO was much easier to train - we only had to train it once. Whereas for RLHF we had to do the Reward Modeling first and then use it for fine tuning of the main LLM.\n",
        "\n",
        "Now, run everything and tell us what you think about the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Tj1ll4LiBH5z",
        "outputId": "a96d91eb-5497-4339-f6a8-fafdc4faa528"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table style=\"border:1px solid black\" >\n",
              "  <tr>\n",
              "    <th style=\"text-align: center; border:1px solid black\">PREFIX</th>\n",
              "    <th style=\"text-align: center; border:1px solid black\">PRETRAIN</th>\n",
              "    <th style=\"text-align: center; border:1px solid black\">SFT</th>\n",
              "    <th style=\"text-align: center; border:1px solid black\">RLHF</th>\n",
              "    <th style=\"text-align: center; border:1px solid black\">DPO</th>\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`What`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">What is the best way to take photos? For me I prefer to take pictures from a tripod. I normally take pictures using a tripod with an adapter to adapt it to my camera (such as a Leica). It works well though I found that the first time. I did the photo tutorial, but when I tried it</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">What would you do with the time?\"\n",
              "\n",
              "What about the money? It's not enough to go the normal avenue of getting a lawyer, but just the thought of going to school is so great.\n",
              "\n",
              "\"Don't you mean I don't have that money?\"\n",
              "\n",
              "That would be nice, I think,</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">What was also in the early days of that campaign, I am told, were allegations that he had a mistress to act as his chief of staff; or a mistress named Laura, whose existence had never been disclosed by Mrs. Clinton. It is hard to take a little scandal to run a campaign. And that was a scandal</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">What's the deal?\n",
              "\n",
              "The original goal of the Kickstarter campaign was to fund the development of a new game based on the \"The Game That Will Never Die\" series, to be released for PC. Due to the incredible response to the Kickstarter, the developer is now bringing a modernised and improved version of this game</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Who are you`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Who are you? What are you doing here? Do you have any intention of stealing my life? Oh, my God, I'm your own nightmare in here. You're so stupid, you can't even see my mind. There must be some mistake. Let me look inside you. You're all the way inside me! I</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Who are you doing this for?\"\n",
              "\n",
              "\"I… I don't know, but I was looking for something like that, but I do know of some that are called \"magic stones, crystal discs!\" I was just about to try one. I'm going to buy some for a friend of mine at work!\"\n",
              "\n",
              "\"</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Who are you from? I see many names on this list. What is your main interest?\n",
              "\n",
              "What do you do for a living?\n",
              "\n",
              "Which of the following would you like to find as your favorite?\n",
              "\n",
              "How do you spend your weekends?\n",
              "\n",
              "What is the most rewarding thing you do when you finish your</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Who are you taking out to?\"\n",
              "\n",
              "\"Well, if you call someone out you call me.\" – \"I'm just taking out,\" said the girl. …\n",
              "\n",
              "There it is, the very definition of what a \"nice guy\" or \"nice girl\" is. It is, without question, a thing. To</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Give it to`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Give it to the other guys,' she told him.\n",
              "\n",
              "The three of them left, heading off into the night for another time. They were supposed to go back in a day or two. Now they were gone for a week.\n",
              "\n",
              "A few days later, they called each other again, and this time, the new</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Give it to us all?\" I don't know, maybe I said it to my parents and they said, \"We will take it and pass it on to the government,\" but no more than that.\n",
              "\n",
              "So we were at the top of our field and we did, like, 2,000 cycles. So we were doing</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Give it to people who've earned most of their living by using the internet and not writing or working with computers.\"\n",
              "\n",
              "\"When I started, I used the internet a lot, as a way to keep in touch with friends, but now I've moved from that to more productive modes like word processing.\"\n",
              "\n",
              "A computer helps</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Give it to me,\n",
              "\n",
              "And I'll take you home with me\n",
              "\n",
              "Let it go\n",
              "\n",
              "\n",
              "I'd never knew you,\n",
              "\n",
              "We'd been so far apart\n",
              "\n",
              "But the night I kissed you in the car,\n",
              "\n",
              "The love I gave you last night,\n",
              "\n",
              "And the night I gave you a</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Hello, how is`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Hello, how is your day going? Are you at it all? No, just lying there with a ball on your head, and watching your favourite anime characters.\n",
              "\n",
              "I'm not lying, it IS very entertaining when a story has a little bit of logic to it. In some ways, it can be kind of depressing and you</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Hello, how is everyone going? How are you, Dad? I'm well, all I need is some ice cream and some wine. I need to do some things now I'm getting a little bit sleepy after my long trip. Let me talk to you about this later. The children are not allowed to be outside during daylight hours.</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Hello, how is your week going? How could I help you?\"\n",
              "\n",
              "\"It is going well, thanks.\"\n",
              "\n",
              "Then the woman said, \"I'm sorry. But some people are just shy.\"\n",
              "\n",
              "Her tone was so cold I couldn't help but say, \"How could I be so rude?\"\n",
              "\n",
              "\"</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Hello, how is it working?\n",
              "\n",
              "It sounds like things are working as they should - because the new version of the Python interpreter is available to run on the server now, and everything is running fine until someone gives them something to do. You can also verify that by running the Python interactive interpreter for the first time.\n",
              "\n",
              "It</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Do you`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Do you think the government should have the right to collect this data?\"\n",
              "\n",
              "In fact, the House of Representatives recently approved the Privacy Protection Act, the latest effort by Congress to curtail government and corporate spying on Americans. This legislation, passed in late May, is a major shift for America, and will have a significant impact on</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Do you think Hillary Clinton has been too negative about Bernie,\" said Michael Farr, executive assistant to Sen. Joe Manchin (D-WV), who is expected to cast a close vote. \"Does she have a responsibility to tell people who aren't already Democrats it's possible to vote for Bernie and actually help us win</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Do you have kids? (1) What's your favourite food? (2) What's the best thing for your dog? (3) Are you a good parent? (4) Is your dog/cat a companion for pets?\n",
              "\n",
              "Ascribing your choice makes you very interesting to the dog-loving community!</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Do you guys get the point?\n",
              "\n",
              "The same answer to the questions you wrote in the other box.\n",
              "\n",
              "This is because every person, regardless of how important or respected, has exactly the same ability.\n",
              "\n",
              "Here is the truth:\n",
              "\n",
              "You can't learn anything by simply sitting and reading.\n",
              "\n",
              "You</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`The weather is really`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">The weather is really nice, I'm enjoying the ride. I can't wait to see the lake soon.<|endoftext|></pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">The weather is really not bad anymore, so let's bring the party with us!\n",
              "\n",
              "The party starts with our favorite appetizer: Fried Corn with White Sweet Potato and Chickpea Sushi!<|endoftext|></pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">The weather is really unpredictable and there are a few clouds in the forecast. Most of us are just going to hang out at home.\n",
              "\n",
              "I'm not going to be back there again until February 2016. I'll probably call up my old teammates to let them know it's alright for me to go.\n",
              "\n",
              "I feel great!</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">The weather is really good, it was my first day, but everyone says these are snowy and hot.\"\n",
              "\n",
              "The couple went for a walk in the afternoon.\n",
              "\n",
              "\"It was a day with some fog — we took it when it was raining, which we didn't expect,\" he said. \"I liked it and I</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`This person is`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">This person is very good at using the rules against us; they also believe in making people act against their own interests. He is a very intelligent person (a very wise man). The system is in great danger of being overrun. We should go to work immediately and deal with this problem. I will personally go to the White House in</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">This person is the only person I know of who has ever done the work, had all of these resources, all the information, all the things to do this work. I've not seen him in about 15 years.\"<|endoftext|></pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">This person is either a faggot or a pervert, with no idea of what he is talking about. It has nothing to do with what he knows of sex and sexuality. The person is just acting, and acting the way faggots always do.\n",
              "\n",
              "\n",
              "I can only conclude that he just doesn't like women.</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">This person is not a terrorist. A terrorist is someone who has committed a crime. These people were not acting on the orders of the Crown. They did not have a political agenda. They were not motivated by hatred or terror.\"\n",
              "\n",
              "In addition to his criticisms of the decision to name Mohammed, he said the government should have been</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`The world is`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">The world is looking to Russia to take on the task of creating what, in their eyes, is the only real challenge to the supremacy of the US government—and to the Western world more generally,\" wrote Russia's Deputy Foreign Minister Sergei Ryabkov.\n",
              "\n",
              "\"Russia may have good reason to worry about the future that the Americans</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">The world is running out of things to be afraid of. And one of them is us.\" He said the same thing on Sunday, when he took a knee at his locker spot ahead of the game and knelt for prayer.\n",
              "\n",
              "Mortaza got a second chance to make his mark on the game on Sunday against the Knicks</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">The world is changing, and this is only the beginning of a shift.\n",
              "\n",
              "There's an ocean of new technology that's being developed on an almost daily basis by hundreds of small companies that could be harnessed to solve some of the biggest challenges of the next 30 years.\n",
              "\n",
              "There's plenty of room to make a difference</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">The world is filled with people who can not understand the other. In the world, there is no one who can stand on his own two feet and help. And it is only in the world that it is said God has a partner and people can serve. But God cannot serve both sides at the same time.\n",
              "\n",
              "[App</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`I decided to`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">I decided to turn all of their information into a book, \"Riding to the Sea with the Vikings.\" I had no intention of actually writing something, but I was inspired to do so by my experience making the film. So, I wrote three chapters, each with its own subject. The most popular one, about the longship</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">I decided to create a test bed for our next generation of software architecture.\n",
              "\n",
              "The architecture is available here.\n",
              "\n",
              "I also recommend checking out the related post for more.<|endoftext|></pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">I decided to bring some of my own to use. I had several of these made but I had a large number stored away. My son is a strong, but not very good fisherman, so I made some for him.\n",
              "\n",
              "My husband went fishing two times, one with them and another with a friend. Neither of us had</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">I decided to look for a team that offered a chance for me to play at the top level and I joined Newbee. I think they are a great organization and I hope I can do well with their environment.\n",
              "\n",
              "\"I have not received any money from TeamLiquid, I'm still unsure about whether I'll continue with the</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Is it funny`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Is it funny how an entire country of people gets so upset about a silly picture?\" he said. \"Of course it is, it's hilarious. But there was even more stupidity. There was a tweet on the very same day with the exact same photo. Like people should have seen that, if they weren't busy on Twitter or</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Is it funny?\n",
              "\n",
              "Nerds.\n",
              "\n",
              "I hope that's a good thing, but I am having fun playing with all of these new things, and I know I am not the pinnacle of a gamer in any or all of these realms of gaming. As much as it's fun, I am not sure that it</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Is it funny? I don't think it's going to be a comedy show; it's going to be real stuff. You're going to see [the character] getting more comfortable with their new home, and getting a little bit frustrated and a little bit mad.\"I was always a huge Spider-Man fan so that's not</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Is it funny? Of course it is.\n",
              "\n",
              "\"I saw your post, and I thought it was a smart thing to do. If it works, then, I guess I can afford to see it.\"\n",
              "\n",
              "\"Is this something we're doing right now?\"\n",
              "\n",
              "That, at least, is a little more realistic</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Love does`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Love does not require a license (as per our terms of service) so we're not making the show available on the iTunes App Store or in the Google Play Store.\n",
              "\n",
              "We're working with a publishing company for the show (it's not a pay to play arrangement) which can't be reached for comment at this point</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Love does not end its life as a victim of any kind of cruelty. For a while in fact, such cruelty might cause the end of that life to be painful or, even more often, the end of it to be cruel. This is not surprising since most organisms in the wild will not survive a harsh environment in which they</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Love does not follow the teachings of Buddha. I prefer the good life and do not believe in the Buddha's instructions,\" she said.<|endoftext|></pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Love does not have any of the restrictions that we had to go through with some companies in the UK and Europe.\"\n",
              "\n",
              "He said: \"In our view, having been out of the home market for many years, our approach has been to stay within the legal areas of the UK and move to a location in order to benefit</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Friends are`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Friends are a huge part of you,\" said Elam. \"But I also look at it as a gift at the same time. How you get people out and in the world, how you provide a place for hope, and how you empower women to speak their minds. I just think that's what happens when you have good</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Friends are also important to us, so I'd encourage you to keep an eye on them. When you get a message about a friend, give them a ring and say hello!\n",
              "\n",
              "If you're making changes to your own life, ask your friends if they would mind recommending you things to help you find your way in life</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Friends are best.\"\n",
              "\n",
              "\"I did something to ruin your relationship with friends, I suppose.\"\n",
              "\n",
              "\"I am sorry, but it was nothing bad. I didn't mean to hurt you.\"\n",
              "\n",
              "\"No, I didn't see anything wrong doing it.\"\n",
              "\n",
              "Riley was silent, he was the one</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Friends are coming home to their families. It's just the way it is.\"\n",
              "\n",
              "In the aftermath of the murder, the city's police officers have worked with families, community groups, faith leaders, law enforcement and victims' families to help rebuild the community. The Police Survivors Association of New Orleans, an initiative to establish a</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`The earth is`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">The earth is a lot smaller than you realize,\" he says with a slight smile. \"When you go out and look, you're gonna see a lot more of it than you realize. You see all kinds of stuff that you think were gone.\"\n",
              "\n",
              "With all the destruction wrought by the Civil War, there were good reasons to</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">The earth is flat. But in the beginning was the waters. When God formed the world, he separated the water into four seas and separated the dry land by them.\" (Genesis 1:3.)\n",
              "\n",
              "God created the sky and the ocean, and all living things, and all of mankind!\n",
              "\n",
              "Why? Because God</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">The earth is a home.\"\n",
              "\n",
              "— The Book\n",
              "\n",
              "There are so much we'd like to be happy. When a young man is asked what makes us happy, he says:\n",
              "\n",
              "\"Nothing. There is nothing to be happy about.\"\n",
              "\n",
              "— Martin Luther King\n",
              "\n",
              "\"The earth is full of joy.</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">The earth is a fragile planet with a high chance of destruction due to natural disasters and war.<|endoftext|></pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Red color means`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Red color means 'blue'\n",
              "\n",
              "Sizes available:\n",
              "\n",
              "Small/Medium/Large\n",
              "\n",
              "*Small to Medium Size T-Shirt is a white shirt with a blue color.\n",
              "\n",
              "\n",
              "Small/Medium/Large Size X-Shirt is a black tee with a blue color.\n",
              "\n",
              "\n",
              "If you want these colors</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Red color means the game has been saved in the dark room\n",
              "\n",
              "Gray-colored means the game has been saved in the bright room\n",
              "\n",
              "And, of course, the room in which the game was played.<|endoftext|></pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Red color means that you have reached the'red-state' of the game. That is a state with the most amount of actions per month, but also the worst amount of action progress. The most successful and balanced decks play in the Red Zone, so that's what you want. If nothing else, you are going to want</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Red color means that the area of the light source is redder. Green color means that the area of the light source is greender. This is because the wavelengths of light arriving from the Earth's atmosphere that are absorbed and converted into the colours of red, green and blue by the human eye are so concentrated in this range that they</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Waves move wind`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Waves move wind. Wind is the most important factor in the life of any sailboat and in the life of any sail boat is defined as the speed or direction of the winds.\n",
              "\n",
              "While some studies make the correlation between wind speed and durability in the sailboat industry, it is often misunderstood. For instance, if a wind speed</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Waves move wind with your movement, creating different wind conditions by changing the rate of change. These properties also help to control your performance when changing the wind flow.\n",
              "\n",
              "The first three rules are generally found amongst the most common wind laws, and you can find these for yourself in the table to the right. To get your own wind</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Waves move wind. In a vacuum, you just need the wind to move any number of air molecules. In a vacuum, air can never change shape; in a medium that acts like a liquid, it can. That will be the same in a water balloon. Even with the air of a balloon, the pressure is going to be</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Waves move wind power to the other side.\n",
              "\n",
              "Wind speeds are not the only environmental issue. Currents and noise generate the same effect of a pollutant. The environment contributes to climate change and health.\n",
              "\n",
              "The effects of wind and weather on these issues can be devastating - for the animals, people, and their land.</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Bear lives in`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Bear lives in her car at the family's apartment in Port Coquitlam, B.C. (CBC)\n",
              "\n",
              "Heather's father, Bruce Rennison, a former RCMP officer, was a member of the force for 50 years. Although she had not been convicted of a Criminal Code offence, she had been charged with</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Bear lives in the Midwest and writes from home.<|endoftext|></pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Bear lives in a place that's very different than the other cities, where there's a very different kind of lifestyle for the locals.\n",
              "\n",
              "So when you get into it and you find out what's going on, it's not always pretty. In my day to day life, there's a lot more work to do in terms</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Bear lives in northern California, about 30 miles away from his family. He has lost and found his way to this campground, but only because of its wonderful, friendly staff. For those who are visiting the park and cannot afford to purchase a rental, he recommends the Campground's online camping reservation option to save money and enjoy a</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`There is no`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">There is no need for such a rule. What our members and their families want has nothing to do with how the government does things.\"\n",
              "\n",
              "Conservative Party candidate Mary Lou McDonald is an advocate of a \"right to die\" bill. (CBC)\n",
              "\n",
              "But she says that even that change — which was added as an amendment to</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">There is no way to make them pay.\" \"I'm sorry.\" \"Can you give me something to sleep on for tonight?\" \"No thanks.\" \"Can it wait for the day before you've to go back to work?\" The girl replied, feeling completely out of options. She was also worried about what she would do to her</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">There is no point of saying that it is possible in a simple matter,\" says Dr. Richard E. Reis, a pediatric surgeon at the University of Texas Medical Branch in Galveston, Texas, who has treated children who had had cancer. The same is true for a lot of the other common diseases.\n",
              "\n",
              "That includes</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">There is no question that we should seek to create a climate where everyone can speak and have their voice be heard; there is no question of getting in the way, and we cannot compromise that, which is why these new regulations are so crucial.\n",
              "\n",
              "The reality is these regulations make it mandatory that companies disclose how climate change impacts on</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`There are many`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">There are many benefits to having a flexible work schedule, but don't be afraid to leave some tasks to chance. When you take a break for a long flight and wonder, \"What should I do to start fresh,\" consider the following ideas:\n",
              "\n",
              "1. Ask friends, family, and co-workers at home about their travel</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">There are many other points in my essay where we have to stop and ask ourselves, \"what can we do on the macro-level to avoid this?\"<|endoftext|></pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">There are many questions to be asked about the origins of the world's oceans before they formed. But what are the answers? This article will focus only on how these questions can be answered. It assumes, through careful study of the physical evidence for and from the evidence for the evolution of sea-bacteria, that the history of the</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">There are many factors that go into the quality of a team which can help a team look better, but the biggest is it makes your team stronger.<|endoftext|></pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Armin is exceptional`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Armin is exceptional!\"\n",
              "\n",
              "Towards this the man was dumbfounded, \"How is that possible?\"\n",
              "\n",
              "There was no doubt that it was the effect of a divine weapon, but then, if he didn't think, then he also couldn't know why the person was like this…\n",
              "\n",
              "\"S-Shut up</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Armin is exceptional for his ability to use the information to his true advantage. If Gengar used his intelligence, he would have used more subtle tactics to sneak through the door instead of getting through the main entrance undetected. He's also the last one to actually go in the game as per usual.\n",
              "\n",
              "Gengar should</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Armin is exceptional in the area of technical management and his vision is very appealing.\"\n",
              "\n",
              "Roland also had to deal with the issue of getting his team to buy the gear they needed for the first couple of races.\n",
              "\n",
              "\"I can't say enough about the calibre of the guys that are involved with this, the technical</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Armin is exceptional. Not only was he a very efficient defender last season, but he could have made an impact not just with their defense but also with other aspects of the team's game, as his strong on-the-ball skills and his defensive playmaking was well-received by the coaching staff last season. He also showed his</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`All I need for Christmas`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">All I need for Christmas is a big ham, a big kettle of soup, a dollop of cheese.\n",
              "\n",
              "It's more than that\n",
              "\n",
              "But if you don't mind that, I would just like a ham in your mouth, is it?\n",
              "\n",
              "If you are a woman, you can just like my son, too,</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">All I need for Christmas is my iPhone 4. If you want to help, do it. Thanks.\"\n",
              "\n",
              "\"Thanks for the post.\" - I can add my phone number and email too.\n",
              "\n",
              "\n",
              "You are doing all of this so that people can make donations, not just a thank you for a comment like this. A little charity</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">All I need for Christmas is a gift! (sucks to look at those pictures and hear everyone yelling, but that's how it goes. :) )<|endoftext|></pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">All I need for Christmas, I'd give away nothing,\" he says. \"I'd give away something to the people that are working hard to get ahead, help them out.\"\n",
              "\n",
              "And, according to the U.S. Chamber of Commerce, the average hourly wage is $23, compared with $10 for McDonald's. \"There</pre></td>\n",
              "\n",
              "  </tr>\n",
              "  <tr>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`Whenever, wherever`</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Whenever, wherever, we may find ourselves. At home they are our home. In the streets they are our home. On the beaches they are our home. They are our home. We will build our world on water. This city of mine is the water. We love to ride our surfboards around on the water, even when</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Whenever, wherever the power of my mind and my imagination can be harnessed, and the beauty of human life can be wrought through the power of the minds and the imaginations of the children of this land.\n",
              "\n",
              "You need only to tell me a story to get a man to come to the rescue, and then I can make</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Whenever, wherever anyone is allowed, the use of my name is the best thing it is possible to do. If there's no right to do or a right of people to be a member of an organization, it is not allowed.\n",
              "\n",
              "And I do not know how it happened to be this way now.\n",
              "\n",
              "You have</pre></td>\n",
              "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">Whenever, wherever you feel a spark, we're there for you.\"\n",
              "\n",
              "A couple of months ago, I walked down the narrow corridor, down to the next station, not knowing where I was going, but knowing where I was, so that I could continue moving forward, and I knew I was never going to stop. I</pre></td>\n",
              "\n",
              "  </tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import HTML, display\n",
        "table_template = \"\"\"<table style=\"border:1px solid black\" >\n",
        "  <tr>\n",
        "    <th style=\"text-align: center; border:1px solid black\">PREFIX</th>\n",
        "    <th style=\"text-align: center; border:1px solid black\">PRETRAIN</th>\n",
        "    <th style=\"text-align: center; border:1px solid black\">SFT</th>\n",
        "    <th style=\"text-align: center; border:1px solid black\">RLHF</th>\n",
        "    <th style=\"text-align: center; border:1px solid black\">DPO</th>\n",
        "  </tr>\n",
        "{}\n",
        "</table>\"\"\"\n",
        "\n",
        "row_template = '''  <tr>\n",
        "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">`{}`</pre></td>\n",
        "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">{}</pre></td>\n",
        "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">{}</pre></td>\n",
        "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">{}</pre></td>\n",
        "    <td style=\"width:20%; border:1px solid black\"><pre align=\"left\">{}</pre></td>\n",
        "\n",
        "  </tr>'''\n",
        "\n",
        "rows = []\n",
        "\n",
        "for i, prefix in enumerate(prefixes):\n",
        "    # replace placeholders in the format() arguments\n",
        "    rows.append(row_template.format(prefix, pre_train_outputs[i], sft_outputs[i], dpo_outputs[i], rlhf_outputs[i]))\n",
        "\n",
        "display(HTML(table_template.format('\\n'.join(rows))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZ9K_zGFV4Ir"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "10324501437f4f03b8498331d290df67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ed03d5217b34235aa79fbc964b6ea65",
              "IPY_MODEL_62e71597775c43a393481f2a55d40ea7",
              "IPY_MODEL_cd43f60d2f8849b7b3aab43f4ca51995"
            ],
            "layout": "IPY_MODEL_41f3f0ad0bd1408b8800db2f005bfc75"
          }
        },
        "1e22981150a543059b1f3351342c5bb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ed03d5217b34235aa79fbc964b6ea65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40b9a931bc1a478ab5c9e9315887075b",
            "placeholder": "​",
            "style": "IPY_MODEL_e2d50dd8323342c3acf8a225ab01b836",
            "value": " 18%"
          }
        },
        "40b9a931bc1a478ab5c9e9315887075b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41f3f0ad0bd1408b8800db2f005bfc75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42d3354a2c9a436bb057560c9fb7f3a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fae5cd824994607ba1e9c8cfb2d1886": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54eeca9bf8fa47b5a4759d04e54101f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdb0550069244bffbf5343bb5e2f2246",
            "placeholder": "​",
            "style": "IPY_MODEL_4fae5cd824994607ba1e9c8cfb2d1886",
            "value": " 5009/5009 [00:08&lt;00:00, 431.90 examples/s]"
          }
        },
        "61b839e416384072bc223da810c64444": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62e71597775c43a393481f2a55d40ea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65ed70e4aebe45e58f0afc015e037540",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9983e6e40fc4f6cad35a756e4ea8b30",
            "value": 35
          }
        },
        "656bf6ed92974d6caaf9d61d22a74328": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42d3354a2c9a436bb057560c9fb7f3a0",
            "max": 5009,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e22981150a543059b1f3351342c5bb5",
            "value": 5009
          }
        },
        "65ed70e4aebe45e58f0afc015e037540": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7631b25381854ab481da424eeae0f202": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a607a4f779e4f8f8d1ca46f3696b364",
              "IPY_MODEL_656bf6ed92974d6caaf9d61d22a74328",
              "IPY_MODEL_54eeca9bf8fa47b5a4759d04e54101f1"
            ],
            "layout": "IPY_MODEL_e649ed113c324a60ad14fb11362bb91f"
          }
        },
        "7b35232c81364d78ac312ace0eef2c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a607a4f779e4f8f8d1ca46f3696b364": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61b839e416384072bc223da810c64444",
            "placeholder": "​",
            "style": "IPY_MODEL_8f161a2c48db4eca8a46e7353d53dbc6",
            "value": "Map: 100%"
          }
        },
        "8f161a2c48db4eca8a46e7353d53dbc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9983e6e40fc4f6cad35a756e4ea8b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bdb0550069244bffbf5343bb5e2f2246": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2453eaa728044fab918db2f0a1d085f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd43f60d2f8849b7b3aab43f4ca51995": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2453eaa728044fab918db2f0a1d085f",
            "placeholder": "​",
            "style": "IPY_MODEL_7b35232c81364d78ac312ace0eef2c5d",
            "value": " 35/200 [10:37&lt;47:32, 17.29s/it]"
          }
        },
        "e2d50dd8323342c3acf8a225ab01b836": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e649ed113c324a60ad14fb11362bb91f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2be6d1a4389c4fbbaec73860fd68e71a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7c232ebcd53452e97ee2632f5504c0f",
              "IPY_MODEL_56375209471e4287b44646a6a997ead7",
              "IPY_MODEL_1ef4b276f74a4a7fb69834ee2f4afbff"
            ],
            "layout": "IPY_MODEL_be6e07cffa6f47f48d5027df982ad286"
          }
        },
        "a7c232ebcd53452e97ee2632f5504c0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7db6df03e8974e448412e6ed35f4af2e",
            "placeholder": "​",
            "style": "IPY_MODEL_89311f83ec9e49499b38215eede68835",
            "value": "Downloading readme: 100%"
          }
        },
        "56375209471e4287b44646a6a997ead7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73837584dcd946b781add2821eda08b2",
            "max": 10606,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f03270bafd4546c8819510fae43f75fb",
            "value": 10606
          }
        },
        "1ef4b276f74a4a7fb69834ee2f4afbff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23577d3f644e47108984a8f39420023b",
            "placeholder": "​",
            "style": "IPY_MODEL_3d9c822d338143e48932c8eeedf02a19",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 470kB/s]"
          }
        },
        "be6e07cffa6f47f48d5027df982ad286": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7db6df03e8974e448412e6ed35f4af2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89311f83ec9e49499b38215eede68835": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73837584dcd946b781add2821eda08b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f03270bafd4546c8819510fae43f75fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23577d3f644e47108984a8f39420023b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d9c822d338143e48932c8eeedf02a19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffed507e079547a09f5d9deda3b8192a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5b37ecb1a1c45dfaa9587e40d580de9",
              "IPY_MODEL_c6049ac20aac40c6adee4f66b2ea9e59",
              "IPY_MODEL_3d58139c7b75467bb47c141d02201da0"
            ],
            "layout": "IPY_MODEL_236cbbe409b643b9842d06ec9b67d54f"
          }
        },
        "d5b37ecb1a1c45dfaa9587e40d580de9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_377538d73ad343c3ac18bc3d516e4fd1",
            "placeholder": "​",
            "style": "IPY_MODEL_eacc4bb6ac594e99a1f4ef5b4dd03d62",
            "value": "Downloading data: 100%"
          }
        },
        "c6049ac20aac40c6adee4f66b2ea9e59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1059d2c394448bc856209da4dc875de",
            "max": 63494018,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e16736db75b4bd59101bec4ce5cffa6",
            "value": 63494018
          }
        },
        "3d58139c7b75467bb47c141d02201da0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f4b69544e284578ad2aceedc0c1d8b4",
            "placeholder": "​",
            "style": "IPY_MODEL_d18bdaec02db4853a3223a76e2c06454",
            "value": " 63.5M/63.5M [00:02&lt;00:00, 29.2MB/s]"
          }
        },
        "236cbbe409b643b9842d06ec9b67d54f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "377538d73ad343c3ac18bc3d516e4fd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eacc4bb6ac594e99a1f4ef5b4dd03d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1059d2c394448bc856209da4dc875de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e16736db75b4bd59101bec4ce5cffa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f4b69544e284578ad2aceedc0c1d8b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d18bdaec02db4853a3223a76e2c06454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f7672f51d204513ad3e81e6b5d247a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e022ec4ec184607bc56eb6d707be8ca",
              "IPY_MODEL_4cc55d1db953463488589a9ec005a54f",
              "IPY_MODEL_ee98e70ff406423190d69bb15299fbe0"
            ],
            "layout": "IPY_MODEL_50854ec54b9b4305a1c19d8af7498a4f"
          }
        },
        "0e022ec4ec184607bc56eb6d707be8ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a35e896df744e799abccbede8e6eaba",
            "placeholder": "​",
            "style": "IPY_MODEL_c2ebe39397614fe0ba63faf04726a5d5",
            "value": "Downloading data: 100%"
          }
        },
        "4cc55d1db953463488589a9ec005a54f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e67378226aaa4b949c5ed20396889ff3",
            "max": 3180111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d013cc332e5458ab362cdc526c06290",
            "value": 3180111
          }
        },
        "ee98e70ff406423190d69bb15299fbe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a611ac4e65b8489b855163ae1956135b",
            "placeholder": "​",
            "style": "IPY_MODEL_59d7752ce45547da89ae4b2ee37ac376",
            "value": " 3.18M/3.18M [00:00&lt;00:00, 12.5MB/s]"
          }
        },
        "50854ec54b9b4305a1c19d8af7498a4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a35e896df744e799abccbede8e6eaba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2ebe39397614fe0ba63faf04726a5d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e67378226aaa4b949c5ed20396889ff3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d013cc332e5458ab362cdc526c06290": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a611ac4e65b8489b855163ae1956135b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59d7752ce45547da89ae4b2ee37ac376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52eb644c5e6e4f6581ae60c8e07d1216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_176df7aa05e847e39a7b17998ddbab4d",
              "IPY_MODEL_f63df76e6a5e41c196aa6f358c71b14d",
              "IPY_MODEL_0e76e29c831249529a768d3f3a9cfef9"
            ],
            "layout": "IPY_MODEL_15bf3083113444098c873ed079ef300d"
          }
        },
        "176df7aa05e847e39a7b17998ddbab4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bc7bc2a057545659ddb484e56476455",
            "placeholder": "​",
            "style": "IPY_MODEL_c7f55ec79595403596b6aa01a0da268c",
            "value": "Generating train split: 100%"
          }
        },
        "f63df76e6a5e41c196aa6f358c71b14d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a59bc7c9a1b94a15a7a57aa502ee6472",
            "max": 128575,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c96c1c616bd44d419dadb6e4fcd8c514",
            "value": 128575
          }
        },
        "0e76e29c831249529a768d3f3a9cfef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c56f4aaded542d591f570fe50f8e754",
            "placeholder": "​",
            "style": "IPY_MODEL_d94bfb75e5e14804ba9ebd9eb401038f",
            "value": " 128575/128575 [00:01&lt;00:00, 61861.15 examples/s]"
          }
        },
        "15bf3083113444098c873ed079ef300d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bc7bc2a057545659ddb484e56476455": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7f55ec79595403596b6aa01a0da268c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a59bc7c9a1b94a15a7a57aa502ee6472": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c96c1c616bd44d419dadb6e4fcd8c514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c56f4aaded542d591f570fe50f8e754": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d94bfb75e5e14804ba9ebd9eb401038f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78fde2d5e96446c9ab14b6df319a0367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21c9ec40804647cfa7f12b57da23e1f9",
              "IPY_MODEL_d2025aefb0694c26ae4d13b89872cacf",
              "IPY_MODEL_810aa05821dc4cb6882a8f8ada57a0be"
            ],
            "layout": "IPY_MODEL_20eb2636869a4df7a462ee337c154f44"
          }
        },
        "21c9ec40804647cfa7f12b57da23e1f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_656fc68953bd49ba8e41ec42c28368ca",
            "placeholder": "​",
            "style": "IPY_MODEL_1bfae02126334b0d87b33b7a4ff1f774",
            "value": "Generating validation split: 100%"
          }
        },
        "d2025aefb0694c26ae4d13b89872cacf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acb3194e2fa5414c848092fe8c1b75c0",
            "max": 6599,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77f828673e3a453baf6200d3de645a9a",
            "value": 6599
          }
        },
        "810aa05821dc4cb6882a8f8ada57a0be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fa7c6506e774b68b4a86f0c3dc964fb",
            "placeholder": "​",
            "style": "IPY_MODEL_98c0669673b944dabe58f14bdf437254",
            "value": " 6599/6599 [00:00&lt;00:00, 54105.40 examples/s]"
          }
        },
        "20eb2636869a4df7a462ee337c154f44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "656fc68953bd49ba8e41ec42c28368ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bfae02126334b0d87b33b7a4ff1f774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acb3194e2fa5414c848092fe8c1b75c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77f828673e3a453baf6200d3de645a9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6fa7c6506e774b68b4a86f0c3dc964fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98c0669673b944dabe58f14bdf437254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8afcf9fe28474c008711024e55e53a7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16c3598210b64e88822818e0e5c17cf1",
              "IPY_MODEL_4ca37163d0604ece8b867b6c9746fbea",
              "IPY_MODEL_cf777f03bc2f49f09a1785ff79d2b580"
            ],
            "layout": "IPY_MODEL_1d7f5b137a4f409e889b45be8a9d1423"
          }
        },
        "16c3598210b64e88822818e0e5c17cf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97ff05fd85374c68b562bc0757ed17b0",
            "placeholder": "​",
            "style": "IPY_MODEL_5efe42e16ad34f138bcb4eff21eb5292",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "4ca37163d0604ece8b867b6c9746fbea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54721e3fb59b489bb0f3743df43781a9",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf770eef0a434ee297e10aaee0c45bc7",
            "value": 26
          }
        },
        "cf777f03bc2f49f09a1785ff79d2b580": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12ffcd77c2de4b7ba32eab2ba42a5709",
            "placeholder": "​",
            "style": "IPY_MODEL_24f4706959aa43bf9f3a0178dae4c969",
            "value": " 26.0/26.0 [00:00&lt;00:00, 1.71kB/s]"
          }
        },
        "1d7f5b137a4f409e889b45be8a9d1423": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97ff05fd85374c68b562bc0757ed17b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5efe42e16ad34f138bcb4eff21eb5292": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54721e3fb59b489bb0f3743df43781a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf770eef0a434ee297e10aaee0c45bc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12ffcd77c2de4b7ba32eab2ba42a5709": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24f4706959aa43bf9f3a0178dae4c969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "430a287bd71e4324b970a651d521eb97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06fe74e7d39c47ecb8d58b2c659d7b9e",
              "IPY_MODEL_c274079b869641c1bf4ff63593e6e52f",
              "IPY_MODEL_60a37fbd5ac149418f6369cd3386861f"
            ],
            "layout": "IPY_MODEL_7799f60b532641e2b222a04ea10b4116"
          }
        },
        "06fe74e7d39c47ecb8d58b2c659d7b9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1da0cb746242449799b66d55d76d467a",
            "placeholder": "​",
            "style": "IPY_MODEL_5ef2c131bfe64e59a137e8a4d83db287",
            "value": "config.json: 100%"
          }
        },
        "c274079b869641c1bf4ff63593e6e52f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_240672bde6c7452bbf80ce049dbe13f1",
            "max": 666,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0279eaf4472d4ee3abb414d74766691e",
            "value": 666
          }
        },
        "60a37fbd5ac149418f6369cd3386861f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a69b8c1e426b4a1e8c3a17bb4be51f2f",
            "placeholder": "​",
            "style": "IPY_MODEL_8f4ca337966a4b3a9b0ebe0219b0f604",
            "value": " 666/666 [00:00&lt;00:00, 49.2kB/s]"
          }
        },
        "7799f60b532641e2b222a04ea10b4116": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1da0cb746242449799b66d55d76d467a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ef2c131bfe64e59a137e8a4d83db287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "240672bde6c7452bbf80ce049dbe13f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0279eaf4472d4ee3abb414d74766691e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a69b8c1e426b4a1e8c3a17bb4be51f2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f4ca337966a4b3a9b0ebe0219b0f604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "615f7e47d67341d7b0360db5c5f35434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f310124ff9c5419ea60cfb4ff56612b3",
              "IPY_MODEL_ef33feedd29941488fa9814323f464c4",
              "IPY_MODEL_23a30e4563634c4fae3594665710b99d"
            ],
            "layout": "IPY_MODEL_57e4a8bc30d04b06ad583994e51ae7f8"
          }
        },
        "f310124ff9c5419ea60cfb4ff56612b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca19c27cc70d409fb1598e6b00bc9686",
            "placeholder": "​",
            "style": "IPY_MODEL_2a7767fd7cd94c45a80b6053cca1e274",
            "value": "vocab.json: 100%"
          }
        },
        "ef33feedd29941488fa9814323f464c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dd2546967db40efa7fb7e074366f68e",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d680f2e7a77b476485f481b05f9250f3",
            "value": 1042301
          }
        },
        "23a30e4563634c4fae3594665710b99d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e35e264a7a324b419dd9703c35d81447",
            "placeholder": "​",
            "style": "IPY_MODEL_0ab28ab4e9e14e648b10c9d75915de53",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 8.54MB/s]"
          }
        },
        "57e4a8bc30d04b06ad583994e51ae7f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca19c27cc70d409fb1598e6b00bc9686": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a7767fd7cd94c45a80b6053cca1e274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5dd2546967db40efa7fb7e074366f68e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d680f2e7a77b476485f481b05f9250f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e35e264a7a324b419dd9703c35d81447": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ab28ab4e9e14e648b10c9d75915de53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9daaabb06b1f4c6597ce742c50aed2e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_816627d01b114c398bca0caafa6907e3",
              "IPY_MODEL_b719cf24402343df99858e9bdf111721",
              "IPY_MODEL_cca0cd6f1cef43919957661d0490ab28"
            ],
            "layout": "IPY_MODEL_760f4efaef03472c94494c74d96a114d"
          }
        },
        "816627d01b114c398bca0caafa6907e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5f40e5a3d244346a65cf208547f664f",
            "placeholder": "​",
            "style": "IPY_MODEL_b0f0e6cfc79f43c29170c2c998430d46",
            "value": "merges.txt: 100%"
          }
        },
        "b719cf24402343df99858e9bdf111721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd5ae5e3032d437eb5182429cd0a97c3",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_140770eb82324946ab29ff0ee6460d29",
            "value": 456318
          }
        },
        "cca0cd6f1cef43919957661d0490ab28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53b11b30c1ec41f8b98cb2ddd3e6692f",
            "placeholder": "​",
            "style": "IPY_MODEL_a2d2d1ddd57f4c76b9274edaae7cf723",
            "value": " 456k/456k [00:00&lt;00:00, 27.1MB/s]"
          }
        },
        "760f4efaef03472c94494c74d96a114d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5f40e5a3d244346a65cf208547f664f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0f0e6cfc79f43c29170c2c998430d46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd5ae5e3032d437eb5182429cd0a97c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "140770eb82324946ab29ff0ee6460d29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53b11b30c1ec41f8b98cb2ddd3e6692f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2d2d1ddd57f4c76b9274edaae7cf723": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5dec9ce9d314342a87d5a5c8de792b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90d71fc30988425b9b6e71d68282b760",
              "IPY_MODEL_940cc4f50ad3413e86f14e49589d0778",
              "IPY_MODEL_ac3dc747d8b2448891101bd83e311551"
            ],
            "layout": "IPY_MODEL_e8b9b490db7942e99a0fa6a0e5b4e254"
          }
        },
        "90d71fc30988425b9b6e71d68282b760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce15e666502144128ec1289b7d750ee3",
            "placeholder": "​",
            "style": "IPY_MODEL_b1cbbaa91a934043ab2878af1463b640",
            "value": "tokenizer.json: 100%"
          }
        },
        "940cc4f50ad3413e86f14e49589d0778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5276702aaa284edfb2fbe6cb244d624b",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58534cfbf58140ddbdd47cd234efbe81",
            "value": 1355256
          }
        },
        "ac3dc747d8b2448891101bd83e311551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9779b9dd1e64939a082ec15f6e32228",
            "placeholder": "​",
            "style": "IPY_MODEL_3e6703bf41784d3db7a22caed1e0a0be",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 12.8MB/s]"
          }
        },
        "e8b9b490db7942e99a0fa6a0e5b4e254": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce15e666502144128ec1289b7d750ee3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1cbbaa91a934043ab2878af1463b640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5276702aaa284edfb2fbe6cb244d624b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58534cfbf58140ddbdd47cd234efbe81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9779b9dd1e64939a082ec15f6e32228": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e6703bf41784d3db7a22caed1e0a0be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66505b3eda3540fead3126fd4a6a4681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_088af93b62024c3aa9976265772363d4",
              "IPY_MODEL_cbe4c29b5d024361ac59def8794594a9",
              "IPY_MODEL_038312e074fe41aa8189f6a6ce9749eb"
            ],
            "layout": "IPY_MODEL_64188f7c3ecf4276b04486467294eb35"
          }
        },
        "088af93b62024c3aa9976265772363d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0169a4a7187f4ff49e816e4b44717375",
            "placeholder": "​",
            "style": "IPY_MODEL_f78805a961fd4fec8ba03ca35c6d037a",
            "value": "model.safetensors: 100%"
          }
        },
        "cbe4c29b5d024361ac59def8794594a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e5237bb66eb4518bab0acd4c5a4aa4c",
            "max": 3247159078,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ee0d5fe184449bf9a9d6cca4baa7376",
            "value": 3247159078
          }
        },
        "038312e074fe41aa8189f6a6ce9749eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c56c379f01b04165987e5e87fe0ed044",
            "placeholder": "​",
            "style": "IPY_MODEL_fcf9a0aae7d442d88c8a6d2480197055",
            "value": " 3.25G/3.25G [00:42&lt;00:00, 97.2MB/s]"
          }
        },
        "64188f7c3ecf4276b04486467294eb35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0169a4a7187f4ff49e816e4b44717375": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f78805a961fd4fec8ba03ca35c6d037a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e5237bb66eb4518bab0acd4c5a4aa4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ee0d5fe184449bf9a9d6cca4baa7376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c56c379f01b04165987e5e87fe0ed044": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcf9a0aae7d442d88c8a6d2480197055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3096c07588749de96514caba6ed2f8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_877becb22fea4192905a50e52b02dc8c",
              "IPY_MODEL_2acec1f6bb9540adb4fd9b01f50fd8a7",
              "IPY_MODEL_b5288487bbab489b93edf265f011bdbc"
            ],
            "layout": "IPY_MODEL_97465f3298934cd3ae216c333cd94a9d"
          }
        },
        "877becb22fea4192905a50e52b02dc8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d31856e4dbf416c846bfa53a3701f01",
            "placeholder": "​",
            "style": "IPY_MODEL_25b6bee185284aa985072f327c3a2c82",
            "value": "generation_config.json: 100%"
          }
        },
        "2acec1f6bb9540adb4fd9b01f50fd8a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47e5a8f5fb604162ab7300d946dc6f79",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd477e35996b495fa2c98d404f3b3297",
            "value": 124
          }
        },
        "b5288487bbab489b93edf265f011bdbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c70cbc857134416ea871d63a3398f00c",
            "placeholder": "​",
            "style": "IPY_MODEL_48eb0342348e45809727a16f93d1da98",
            "value": " 124/124 [00:00&lt;00:00, 7.82kB/s]"
          }
        },
        "97465f3298934cd3ae216c333cd94a9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d31856e4dbf416c846bfa53a3701f01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25b6bee185284aa985072f327c3a2c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47e5a8f5fb604162ab7300d946dc6f79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd477e35996b495fa2c98d404f3b3297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c70cbc857134416ea871d63a3398f00c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48eb0342348e45809727a16f93d1da98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}