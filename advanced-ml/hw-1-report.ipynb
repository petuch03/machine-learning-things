{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/petuch03/machine-learning-things/blob/master/advanced-ml/hw-1-report.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dac30537ef2049b8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Report for 1st homework on Advanced ML course @ Neapolis University Pafos\n",
    "### By Egor Safronov"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bafd64ff5382ad6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### EMforDS\n",
    "\n",
    "The way I completed the task quite direct without any extraordinary things. \n",
    "Starting with creation of required indexes and initializing `self.counts`:\n",
    "```python\n",
    "usr_to_index = {usr: index for index, usr in enumerate(self.usr_arr)}\n",
    "obj_to_index = {obj: index for index, obj in enumerate(self.obj_arr)}\n",
    "lbl_to_index = {lbl: index for index, lbl in enumerate(self.lbl_arr)}\n",
    "\n",
    "self.counts = np.zeros((self.num_usr, self.num_obj, self.num_lbl))\n",
    "for _, row in self.crowd_labels.iterrows():\n",
    "    user_index = usr_to_index[row['user']]\n",
    "    object_index = obj_to_index[row['object']]\n",
    "    label_index = lbl_to_index[row['label']]\n",
    "    self.counts[user_index, object_index, label_index] += 1\n",
    "```\n",
    "Also, `pi` and `rho` required proper initialization:\n",
    "```python\n",
    "# TODO: calculate self.pi and self.rho initial values\n",
    "# init pi and rho with (1 / num_lbl)\n",
    "self.pi = np.full((self.num_usr, self.num_lbl, self.num_lbl), 1 / self.num_lbl)\n",
    "self.rho = np.full(self.num_lbl, 1 / self.num_lbl)\n",
    "```\n",
    "After it, I implemented E and M step of the algorithms. Implementation is quite straightforward, added code marked with original `TODOs` from the task:\n",
    "\n",
    "```python\n",
    "def _e_step(self):\n",
    "    # interation over objects\n",
    "    for i_obj in tqdm(range(self.num_obj), postfix='e_step', leave=False):\n",
    "        # TODO: update self.label_prob\n",
    "        # likelihood pi*counts for the current object, then take the product\n",
    "        i_obj_count = self.counts[:, [i_obj], :]\n",
    "        probs = (self.pi ** i_obj_count).prod(axis=0).prod(axis=1)\n",
    "        # adjust label probabilities\n",
    "        self.label_prob[i_obj] = probs * self.rho\n",
    "        # total probability\n",
    "        total_prob = self.label_prob[i_obj].sum()  # numpy.float64\n",
    "\n",
    "        self.label_prob[i_obj] /= total_prob\n",
    "    return self.label_prob\n",
    "\n",
    "def _m_step(self, posterior):\n",
    "    self.rho = posterior.sum(axis=0) / posterior.sum()\n",
    "\n",
    "    for i_lbl in tqdm(range(self.num_lbl), postfix='m_step', leave=True):\n",
    "        # TODO: update self.pi\n",
    "        error = self.label_prob[:, i_lbl] @ self.counts\n",
    "        total_error = np.sum(error, axis=1, keepdims=True)\n",
    "        for idx in range(total_error.shape[0]):\n",
    "            if total_error[idx] == 0:\n",
    "                self.pi[:, i_lbl, :][idx] = total_error[idx]\n",
    "            else:\n",
    "                self.pi[:, i_lbl, :][idx] = error[idx] / total_error[idx]\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77fa008837ffd917"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Aggregation\n",
    "\n",
    "For implementation of majority voting I used crosstab as it was recommended in the task definition:\n",
    "```python\n",
    "# TODO: majority voting\n",
    "crosstab = pd.crosstab(index=labels['object'], columns=labels['label'])\n",
    "\n",
    "# highest freq for each object\n",
    "majority_vote = crosstab.idxmax(axis=1)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a127f435789668cc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TopicModeling\n",
    "\n",
    "As before, nothing special here. The perplexity implementation:\n",
    "```python\n",
    "log_likelihood = 0\n",
    "for d in range(self.num_docs):\n",
    "    for w in range(self.num_words):\n",
    "        p_wd = np.dot(self.Phi[w, :], self.Theta[:, d])\n",
    "        if self.counts[w, d] > 0:\n",
    "            log_likelihood += self.counts[w, d] * np.log(p_wd)\n",
    "\n",
    "perplexity = np.exp(-log_likelihood / self.total_words)\n",
    "```\n",
    "I slightly modified existing main function, because there were not enough sample (989 instead of 1000). In addition I enriched main with PLSA call itself and building perplexity chart over iterations. The example of how algorithm works:\n",
    "```\n",
    "100%|██████████| 989/989 [00:00<00:00, 1141.98it/s]\n",
    "Iteration 1, Perplexity: 10768.906824213775\n",
    "Iteration 2, Perplexity: 10616.40668455625\n",
    "Iteration 3, Perplexity: 10487.47569407712\n",
    "Iteration 4, Perplexity: 10352.93221999247\n",
    "Iteration 5, Perplexity: 10203.646477272394\n",
    "Iteration 6, Perplexity: 10040.59522358958\n",
    "Iteration 7, Perplexity: 9872.388951368635\n",
    "Iteration 8, Perplexity: 9710.43408993396\n",
    "Iteration 9, Perplexity: 9563.663291295508\n",
    "Iteration 10, Perplexity: 9436.368212821286\n",
    "Iteration 11, Perplexity: 9328.786985044177\n",
    "Iteration 12, Perplexity: 9238.741548370568\n",
    "Iteration 13, Perplexity: 9163.118996773246\n",
    "Iteration 14, Perplexity: 9099.079984956297\n",
    "Iteration 15, Perplexity: 9044.73464884072\n",
    "Iteration 16, Perplexity: 8998.624927363908\n",
    "Iteration 17, Perplexity: 8959.25318839123\n",
    "Iteration 18, Perplexity: 8925.255179170925\n",
    "Iteration 19, Perplexity: 8895.62025030814\n",
    "Iteration 20, Perplexity: 8869.567290846675\n",
    "Iteration 21, Perplexity: 8846.387688449287\n",
    "Iteration 22, Perplexity: 8825.525878778883\n",
    "Iteration 23, Perplexity: 8806.577363358963\n",
    "Iteration 24, Perplexity: 8789.178629966347\n",
    "Iteration 25, Perplexity: 8773.109470298365\n",
    "Iteration 26, Perplexity: 8758.34828473269\n",
    "Iteration 27, Perplexity: 8744.917724498344\n",
    "Iteration 28, Perplexity: 8732.829379287385\n",
    "Iteration 29, Perplexity: 8722.03794300073\n",
    "Iteration 30, Perplexity: 8712.413782348347\n",
    "Topic #1:\n",
    "на, работы, опыт, по, знание, не, от, умение, работать, лет, работ, навыки, до, требования, участие, документации, рф, тк, будет, график\n",
    "Topic #2:\n",
    "работы, 00, контроль, опыт, обязанности, до, условия, требования, от, график, по, организация, ведение, образование, года, заработная, плата, документации, ответственность, 18\n",
    "Topic #3:\n",
    "по, на, условия, для, или, требования, обязанности, образование, за, высшее, при, труда, проведение, 30, рф, от, полный, наличие, оформление, тк\n",
    "Topic #4:\n",
    "работа, на, работы, обязанности, тк, рф, условия, оформление, требования, возможность, за, месяц, по, график, товара, соответствии, роста, оплата, карьерного, профессионального\n",
    "Topic #5:\n",
    "мы, компании, на, для, по, клиентов, возможность, обучение, продаж, россии, сотрудников, от, работа, из, работать, работы, предлагаем, работу, за, компания\n",
    "\n",
    "```\n",
    "The perplexity chart over 30 iterations:\n",
    "![PLSA perplexity over iterations](hw-1.png \"PLSA perplexity over iterations\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1ef43a4a955ac60"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
